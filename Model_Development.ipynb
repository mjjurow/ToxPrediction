{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d66aba5a",
   "metadata": {},
   "source": [
    "# Data Source \n",
    "\n",
    "The model loads 12,707 molecules and their reported toxicity endpoints from the Tox21 data set. Resources and descriptions of the data set are housed here https://tox21.gov/resources/ as well as other places.\n",
    "\n",
    "The data set includes results for commonly tested nuclear receptor assays and stress response assays, which measure how likely a molecule is to cause a problematic interaction with those classes of proteins on cell surfaces."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffc76f4d",
   "metadata": {},
   "source": [
    "# Data Cleaning\n",
    "\n",
    "The data set indexes the tested molecules by the InChIKey, sometimes referred to as a hashed InChI; a fixed length (27 character) condensed digital representation of the InChI that is not human-understandable\n",
    "\n",
    "1) To make the data set useful, the script first converts from InChIKey to InChI, a textual identifier for chemical substances, designed to provide a standard way to encode molecular information and to facilitate the search for such information in databases and on the web\n",
    "    - 201 of the entires had invalid InChIKey values and were removed from the data set (leaving 12,506 entries)\n",
    "\n",
    "2) To allow the database to be searchable by users drawing structures, the inchi is then converted to a Simplified Molecular Input Line Entry System (SMILES), used to translate a chemical's three-dimensional structure into a string of symbols that is easily machine readable.\n",
    "    - 2,500 entries could not convert to SMILES (leaving 10,192 entries). Likely due to stereochemical ambiguity that is a consequence of the loss of dimensionality when converting to a string.\n",
    "    \n",
    "3) Using the RDKit python package, the script then gets 208 unique molecular identifiers for each molecule and stores them in a dataframe\n",
    "    - to avoid drawing conclusions from a very sparse matrix, the script drops any NaN values for each endpoint, leaving 7,377 valid data points in a sufficienty dense matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54f869ee",
   "metadata": {},
   "source": [
    "# Model Development: SVM\n",
    "\n",
    "1) data set is broken into test and train groups\n",
    "2) SVM pipeline is built using the standard scaler and grid search to optimize. Probability is enabled to allow thresholding by certainty\n",
    "\n",
    "# Metrics\n",
    "\n",
    "-Precision: The ratio of correctly predicted positive observations to the total predicted positives. Most useful in cases like this, where the costs of false positives are very high\n",
    "\n",
    "-Recall: The ratio of correctly predicted positive observations to all the observations in the actual class. More important when the cost of false negatives is high\n",
    "\n",
    "-F1 Score: The weighted average of Precision and Recall. This score takes both False Positives and False Negatives into account\n",
    "\n",
    "-ROC Curve and AUC: The Receiver Operating Characteristic (ROC) curve is a plot of the true positive rate against the false positive rate for the different possible cutoffs of a diagnostic test. The Area Under the Curve (AUC) represents the degree or measure of separability. It tells how much the model is capable of distinguishing between classes. The higher the AUC, the better the model is at predicting 0 classes as 0 and 1 classes as 1.\n",
    "\n",
    "confusion matrices presented as usual; \n",
    "- top left: true negative (correctly safe)\n",
    "- top right: false positive (incorrectly predicted toxic, meaning the user would throw out a potentially viable candidate)\n",
    "- bottom left: false negative (incorrectly predicted safe, meaining the user would advance the molecule to animal trials and then it would fail)\n",
    "- bottom right: true positive (correctly predicted toxic)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8528b62",
   "metadata": {},
   "source": [
    "# SVM Performance\n",
    "\n",
    "| Endpoint        | Precision | Recall  | F1 Score | AUC       | Confusion Matrix        |\n",
    "|-----------------|-----------|---------|----------|-----------|-------------------------|\n",
    "| NR.AhR          | 0.7869    | 0.5517  | 0.6486   | 0.8985    | [[1276, 26],<br>[78, 96]]  |\n",
    "| NR.AR           | 0.8409    | 0.5441  | 0.6607   | 0.7531    | [[1589, 7],<br>[31, 37]]   |\n",
    "| NR.AR.LBD       | 0.7872    | 0.6607  | 0.7184   | 0.9158    | [[1475, 10],<br>[19, 37]]  |\n",
    "| NR.Aromatase    | 0.7045    | 0.4627  | 0.5586   | 0.8691    | [[1212, 13],<br>[36, 31]]  |\n",
    "| NR.ER           | 0.7075    | 0.4076  | 0.5172   | 0.7959    | [[1168, 31],<br>[109, 75]] |\n",
    "| NR.ER.LBD       | 0.7907    | 0.4304  | 0.5574   | 0.8175    | [[1482, 9],<br>[45, 34]]   |\n",
    "| NR.PPAR.gamma   | 0.0       | 0.0     | 0.0      | 0.8635    | [[1442, 0],<br>[39, 0]]    |\n",
    "| SR.ARE          | 0.6216    | 0.4423  | 0.5169   | 0.8318    | [[1050, 56],<br>[116, 92]] |\n",
    "| SR.ATAD5        | 0.7632    | 0.3625  | 0.4915   | 0.8756    | [[1547, 9],<br>[51, 29]]   |\n",
    "| SR.HSE          | 0.5882    | 0.2857  | 0.3846   | 0.8005    | [[1405, 14],<br>[50, 20]]  |\n",
    "| SR.MMP          | 0.7926    | 0.6450  | 0.7112   | 0.9364    | [[1062, 39],<br>[82, 149]] |\n",
    "| SR.p53          | 0.7077    | 0.4259  | 0.5318   | 0.8966    | [[1429, 19],<br>[62, 46]]  |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "838ad5fa",
   "metadata": {},
   "source": [
    "# Model Development: Dense Neural Network "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5d19f39",
   "metadata": {},
   "source": [
    "the SVM was ok. Despite the relatively limited data set i tried a simple dense neural network\n",
    "\n",
    "- first layer of 128 (relu activation) with a dropout of 0.5 / second layer 64 (relu) / fed into a sigmoid output layer\n",
    "\n",
    "## Certainty Threhold\n",
    "to optimize the certainty threshold i experimented with one endpoint (NR.ER):\n",
    "\n",
    "| Determinator Threshold | Precision | Recall  | F1 Score | ROC-AUC | Confusion Matrix         |\n",
    "|------------------------|-----------|---------|----------|---------|--------------------------|\n",
    "| 0.5                    | 0.7684    | 0.3967  | 0.5233   | 0.7630  | [[1177, 22],<br>[111, 73]] |\n",
    "| 0.55                   | 0.7711    | 0.3478  | 0.4794   | 0.7704  | [[1180, 19],<br>[120, 64]] |\n",
    "| 0.65                   | 0.8429    | 0.3207  | 0.4646   | 0.7650  | [[1188, 11],<br>[125, 59]] |\n",
    "| 0.75                   | 0.9138    | 0.2880  | 0.4380   | 0.7697  | [[1194, 5],<br>[131, 53]]  |\n",
    "\n",
    "\n",
    "the final threshold was thus set to 0.7, resulting in the below performance metrics of the currently deployed model\n",
    "\n",
    "# DNN Performance\n",
    "\n",
    "| Endpoint         | Precision | Recall  | F1 Score | ROC-AUC | Confusion Matrix         |\n",
    "|------------------|-----------|---------|----------|---------|--------------------------|\n",
    "| NR.AhR           | 0.8710    | 0.4655  | 0.6067   | 0.8961  | [[1290, 12],<br>[93, 81]]  |\n",
    "| NR.AR            | 0.8780    | 0.5294  | 0.6606   | 0.8040  | [[1591, 5],<br>[32, 36]]   |\n",
    "| NR.AR.LBD        | 0.8444    | 0.6786  | 0.7525   | 0.9106  | [[1478, 7],<br>[18, 38]]   |\n",
    "| NR.Aromatase     | 0.8571    | 0.4478  | 0.5882   | 0.8666  | [[1220, 5],<br>[37, 30]]   |\n",
    "| NR.ER            | 0.8182    | 0.3424  | 0.4828   | 0.7704  | [[1185, 14],<br>[121, 63]] |\n",
    "| NR.ER.LBD        | 0.8667    | 0.3291  | 0.4771   | 0.8000  | [[1487, 4],<br>[53, 26]]   |\n",
    "| NR.PPAR.gamma    | 0.9231    | 0.3077  | 0.4615   | 0.8018  | [[1441, 1],<br>[27, 12]]   |\n",
    "| SR.ARE           | 0.7297    | 0.2596  | 0.3830   | 0.8303  | [[1086, 20],<br>[154, 54]] |\n",
    "| SR.ATAD5         | 0.8485    | 0.3500  | 0.4956   | 0.8720  | [[1551, 5],<br>[52, 28]]   |\n",
    "| SR.HSE           | 0.8750    | 0.2000  | 0.3256   | 0.7303  | [[1417, 2],<br>[56, 14]]   |\n",
    "| SR.MMP           | 0.8839    | 0.5931  | 0.7098   | 0.9439  | [[1083, 18],<br>[94, 137]] |\n",
    "| SR.p53           | 0.7895    | 0.4167  | 0.5455   | 0.9205  | [[1436, 12],<br>[63, 45]]  |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f040d99e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3a15fb1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c693a63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d1c506",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1895ee88",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
