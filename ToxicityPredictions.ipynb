{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa3482c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "from scipy import io\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from joblib import dump\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c4bbc2b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.read_csv('full_df')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aecd800f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "30aa3c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoints = ['NR.AhR', 'NR.AR', 'NR.AR.LBD', 'NR.Aromatase', 'NR.ER', 'NR.ER.LBD', 'NR.PPAR.gamma', 'SR.ARE', 'SR.ATAD5', 'SR.HSE', 'SR.MMP', 'SR.p53']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "143c7641",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_columns = ['ID',\n",
    " 'inchikey',\n",
    " 'sdftitle',\n",
    " 'order',\n",
    " 'set',\n",
    " 'CVfold',\n",
    " 'NR.AhR',\n",
    " 'NR.AR',\n",
    " 'NR.AR.LBD',\n",
    " 'NR.Aromatase',\n",
    " 'NR.ER',\n",
    " 'NR.ER.LBD',\n",
    " 'NR.PPAR.gamma',\n",
    " 'SR.ARE',\n",
    " 'SR.ATAD5',\n",
    " 'SR.HSE',\n",
    " 'SR.MMP',\n",
    " 'SR.p53']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bbf79016",
   "metadata": {},
   "outputs": [],
   "source": [
    "desired_column_order = ['ID', 'inchikey', 'inchi', 'SMILES', 'sdftitle', 'order', 'set', 'CVfold'] + [col for col in df.columns if col not in ['ID', 'inchikey', 'inshi', 'SMILES', 'sdftitle', 'order', 'set', 'CVfold']]\n",
    "df_ordered = df[desired_column_order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "88974cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_ordered.head(2)\n",
    "#df_ordered.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ee952cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = df_ordered.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0733f598",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop columns with nan\n",
    "#clean_df_NRAhR = filtered_df_NRAhR.dropna(axis=1).copy()\n",
    "\n",
    "# list whatever didnt have nan\n",
    "#clean_NRAhR_columns = clean_df_NRAhR.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f3c2eb88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inchikey_to_inchi(inchikey):\n",
    "    url = f\"https://pubchem.ncbi.nlm.nih.gov/rest/pug/compound/inchikey/{inchikey}/property/InChI/TXT\"\n",
    "    try:\n",
    "        response = requests.get(url, timeout=10)  # Adding a timeout for the request\n",
    "        if response.status_code == 200:\n",
    "            return response.text.strip()\n",
    "        else:\n",
    "            # Log the error but don't break the process\n",
    "            print(f\"Non-successful response for InChIKey {inchikey}: {response.status_code}\")\n",
    "            return None\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        # Handle request exceptions, like timeouts, connection errors, etc.\n",
    "        print(f\"Request failed for InChIKey {inchikey}: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2251b880",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inchi_to_smiles(inchi):\n",
    "    mol = Chem.MolFromInchi(inchi)\n",
    "    if mol is None:  # Check if RDKit could parse the InChI string\n",
    "        return None\n",
    "    smiles = Chem.MolToSmiles(mol)\n",
    "    return smiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "19d52ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMolDescriptorsFromInchiKey(inchikey, missingVal=None):\n",
    "    inchi = inchikey_to_inchi(inchikey)\n",
    "    if inchi is None:\n",
    "        return None\n",
    "    smiles = inchi_to_smiles(inchi)\n",
    "    if smiles is None:\n",
    "        return None\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    if mol is None:\n",
    "        return None\n",
    "    \n",
    "    return getMolDescriptors(mol, missingVal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2fba4649",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMolDescriptors(mol, missingVal=None):\n",
    "    res = {}\n",
    "    for nm, fn in Descriptors._descList:\n",
    "        try:\n",
    "            val = fn(mol)\n",
    "        except:\n",
    "            val = missingVal\n",
    "        res[nm] = val\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e6151a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMolDescriptorsFromSmiles(smiles, missingVal=None):\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    if mol is None:\n",
    "        return None\n",
    "\n",
    "    res = {}\n",
    "    for nm, fn in Descriptors._descList:\n",
    "        try:\n",
    "            val = fn(mol)\n",
    "        except Exception as e:\n",
    "            print(f\"Error calculating descriptor {nm} for SMILES {smiles}: {e}\")\n",
    "            val = missingVal\n",
    "        res[nm] = val\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "43ef25b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_feature_lists(full_df, target_endpoints):\n",
    "    \"\"\"\n",
    "    input is a dataframe and a list of column names\n",
    "    outputs a list, named feature_[target_endpoint], with all the column titles the model was actually trained with\n",
    "    \"\"\"\n",
    "    for endpoint in target_endpoints:\n",
    "        try:\n",
    "            # Generate molecular descriptors from the SMILES string\n",
    "            descriptors = getMolDescriptorsFromSmiles(smiles)\n",
    "            \n",
    "            # Filter rows with NaN in the target endpoint\n",
    "            filtered_df = full_df.dropna(subset=[target_endpoint])\n",
    "            \n",
    "            # Drop columns with NaN values\n",
    "            clean_df = filtered_df.dropna(axis=1).copy()\n",
    "            \n",
    "            # Define features excluding specific columns\n",
    "            excluded_columns = ['ID', 'inchikey', 'inchi', 'SMILES', 'sdftitle', 'order', 'set', 'inchi', target_endpoint]\n",
    "            features = clean_df.columns.difference(excluded_columns)\n",
    "            \n",
    "            # Select descriptor values for the current SMILES string\n",
    "            descriptor_values = [descriptors[feature] for feature in features if feature in descriptors]\n",
    "            \n",
    "            # Reshape the descriptor values for prediction\n",
    "            descriptor_values_2d = np.array(descriptor_values).reshape(1, -1)\n",
    "            \n",
    "            # Predict the endpoint\n",
    "            prediction = test_sratad5_model.predict(descriptor_values_2d)\n",
    "            \n",
    "            # Print the SMILES string and its predicted endpoint\n",
    "            print(f'SMILES: {smiles}, Predicted Endpoint: {prediction[0]}')\n",
    "        \n",
    "        except Exception as e:\n",
    "            # Handle errors, such as missing descriptors or prediction issues\n",
    "            print(f'Error processing SMILES: {smiles}. Error: {e}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "693596cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_endpoint(endpoint, full_df):\n",
    "    # Step 1: Filter rows with NaN in the target endpoint\n",
    "    filtered_df = df_ordered.dropna(subset=[endpoint])\n",
    "\n",
    "    # Step 2: Drop columns with NaN values\n",
    "    clean_df = filtered_df.dropna(axis=1).copy()\n",
    "\n",
    "    # Step 3: Define features excluding specific columns\n",
    "    features = clean_df.columns.difference(['ID', 'inchikey', 'inchi', 'SMILES', 'sdftitle', 'order', 'set', 'inchi', endpoint])\n",
    "\n",
    "    # Step 4 & 5: Define X and Y\n",
    "    X = clean_df[features].values\n",
    "    y = clean_df[endpoint].values\n",
    "\n",
    "    # Step 6: Check shapes and assert they match\n",
    "    assert X.shape[0] == y.shape[0], f\"Shape mismatch between X and y for endpoint {endpoint}\"\n",
    "\n",
    "    # Step 7: Split into test/train\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Step 8: Parameter grid\n",
    "    param_grid = {\n",
    "        'svc__C': [0.1, 1, 10],\n",
    "        'svc__kernel': ['linear', 'rbf']\n",
    "    }\n",
    "\n",
    "    # Step 9: Create and train the SVM pipeline\n",
    "    svm_pipeline = make_pipeline(StandardScaler(), SVC(probability=True))\n",
    "    grid_search = GridSearchCV(svm_pipeline, param_grid, cv=4, scoring='accuracy', verbose=2)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    best_model = grid_search.best_estimator_\n",
    "\n",
    "    # Step 10: Evaluate the model\n",
    "    predictions = best_model.predict(X_test)\n",
    "    print(f\"Evaluation metrics for endpoint {endpoint}:\")\n",
    "    print(f\"Precision: {precision_score(y_test, predictions)}\")\n",
    "    print(f\"Recall: {recall_score(y_test, predictions)}\")\n",
    "    print(f\"F1 Score: {f1_score(y_test, predictions)}\")\n",
    "    print(f\"AUC: {roc_auc_score(y_test, best_model.predict_proba(X_test)[:, 1])}\")\n",
    "    print(f\"Confusion Matrix:\\n {confusion_matrix(y_test, predictions)}\")\n",
    "\n",
    "    # Save the model\n",
    "    joblib.dump(best_model, f'{endpoint}_svm_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cd540ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    "\n",
    "import joblib  # For saving models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e47a6feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this worked but i want more metrics\n",
    "'''def train_dense_network(X_train, y_train, X_test, y_test):\n",
    "    model = Sequential([\n",
    "        Dense(128, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "        Dropout(0.5),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=50, batch_size=32, verbose=1)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    loss, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "    print(f\"Test Accuracy for endpoint {endpoint}: {accuracy}\")\n",
    "    \n",
    "    return model''';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ce6b4aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_endpoint(endpoint, full_df):\n",
    "    # Step 1: Filter rows with NaN in the target endpoint\n",
    "    filtered_df = full_df.dropna(subset=[endpoint])\n",
    "\n",
    "    # Step 2: Drop columns with NaN values\n",
    "    clean_df = filtered_df.dropna(axis=1).copy()\n",
    "\n",
    "    # Step 3: Define features excluding specific columns\n",
    "    features = clean_df.columns.difference(['ID', 'inchikey', 'inchi', 'SMILES', 'sdftitle', 'order', 'set', 'inchi', endpoint])\n",
    "\n",
    "    # Step 4 & 5: Define X and Y\n",
    "    X = clean_df[features].values\n",
    "    y = clean_df[endpoint].values\n",
    "\n",
    "    # Step 6: Check shapes and assert they match\n",
    "    assert X.shape[0] == y.shape[0], f\"Shape mismatch between X and y for endpoint {endpoint}\"\n",
    "\n",
    "    # Step 7: Split into test/train and scale features\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    scaler = StandardScaler().fit(X_train)\n",
    "    X_train_scaled = scaler.transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    # Train dense network, now including the 'endpoint' argument\n",
    "    model = train_dense_network(X_train_scaled, y_train, X_test_scaled, y_test, endpoint)\n",
    "\n",
    "    # Save the model and scaler\n",
    "    model.save(f'{endpoint}_dense_model.h5')\n",
    "    joblib.dump(scaler, f'{endpoint}_scaler.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d051b05c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_dense_network(X_train, y_train, X_test, y_test, endpoint):\n",
    "    model = Sequential([\n",
    "        Dense(128, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "        Dropout(0.5),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=50, batch_size=32, verbose=1)\n",
    "    \n",
    "    # Generate predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_class = (y_pred > 0.7).astype('int32') #push up the 0.5 to minimize false positives! this could be a slider if wanted\n",
    "\n",
    "    # Calculate metrics\n",
    "    precision = precision_score(y_test, y_pred_class)\n",
    "    recall = recall_score(y_test, y_pred_class)\n",
    "    f1 = f1_score(y_test, y_pred_class)\n",
    "    auc = roc_auc_score(y_test, y_pred)\n",
    "\n",
    "    # Print the evaluation metrics\n",
    "    print(f\"Evaluation Metrics for Endpoint '{endpoint}':\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1 Score: {f1:.4f}\")\n",
    "    print(f\"ROC-AUC: {auc:.4f}\")\n",
    "    print(f\"Confusion Matrix:\\n{confusion_matrix(y_test, y_pred_class)}\")\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "debf562b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "173/173 [==============================] - 0s 814us/step - loss: 0.4231 - accuracy: 0.8567 - val_loss: 0.3414 - val_accuracy: 0.8894\n",
      "Epoch 2/50\n",
      "173/173 [==============================] - 0s 557us/step - loss: 0.3482 - accuracy: 0.8847 - val_loss: 0.3244 - val_accuracy: 0.8901\n",
      "Epoch 3/50\n",
      "173/173 [==============================] - 0s 554us/step - loss: 0.3210 - accuracy: 0.8950 - val_loss: 0.3215 - val_accuracy: 0.8944\n",
      "Epoch 4/50\n",
      "173/173 [==============================] - 0s 552us/step - loss: 0.3111 - accuracy: 0.8924 - val_loss: 0.3131 - val_accuracy: 0.8915\n",
      "Epoch 5/50\n",
      "173/173 [==============================] - 0s 550us/step - loss: 0.2994 - accuracy: 0.8997 - val_loss: 0.3098 - val_accuracy: 0.8930\n",
      "Epoch 6/50\n",
      "173/173 [==============================] - 0s 548us/step - loss: 0.2885 - accuracy: 0.9051 - val_loss: 0.3079 - val_accuracy: 0.8959\n",
      "Epoch 7/50\n",
      "173/173 [==============================] - 0s 557us/step - loss: 0.2842 - accuracy: 0.9051 - val_loss: 0.3075 - val_accuracy: 0.8973\n",
      "Epoch 8/50\n",
      "173/173 [==============================] - 0s 552us/step - loss: 0.2802 - accuracy: 0.9017 - val_loss: 0.3069 - val_accuracy: 0.9002\n",
      "Epoch 9/50\n",
      "173/173 [==============================] - 0s 546us/step - loss: 0.2690 - accuracy: 0.9074 - val_loss: 0.3049 - val_accuracy: 0.8973\n",
      "Epoch 10/50\n",
      "173/173 [==============================] - 0s 572us/step - loss: 0.2704 - accuracy: 0.9112 - val_loss: 0.3075 - val_accuracy: 0.8988\n",
      "Epoch 11/50\n",
      "173/173 [==============================] - 0s 564us/step - loss: 0.2640 - accuracy: 0.9060 - val_loss: 0.3078 - val_accuracy: 0.8930\n",
      "Epoch 12/50\n",
      "173/173 [==============================] - 0s 552us/step - loss: 0.2673 - accuracy: 0.9074 - val_loss: 0.3039 - val_accuracy: 0.8959\n",
      "Epoch 13/50\n",
      "173/173 [==============================] - 0s 574us/step - loss: 0.2580 - accuracy: 0.9103 - val_loss: 0.3069 - val_accuracy: 0.8995\n",
      "Epoch 14/50\n",
      "173/173 [==============================] - 0s 571us/step - loss: 0.2580 - accuracy: 0.9087 - val_loss: 0.3074 - val_accuracy: 0.8995\n",
      "Epoch 15/50\n",
      "173/173 [==============================] - 0s 576us/step - loss: 0.2542 - accuracy: 0.9114 - val_loss: 0.3081 - val_accuracy: 0.8973\n",
      "Epoch 16/50\n",
      "173/173 [==============================] - 0s 560us/step - loss: 0.2522 - accuracy: 0.9149 - val_loss: 0.3151 - val_accuracy: 0.8988\n",
      "Epoch 17/50\n",
      "173/173 [==============================] - 0s 576us/step - loss: 0.2433 - accuracy: 0.9170 - val_loss: 0.3124 - val_accuracy: 0.8915\n",
      "Epoch 18/50\n",
      "173/173 [==============================] - 0s 548us/step - loss: 0.2440 - accuracy: 0.9178 - val_loss: 0.3098 - val_accuracy: 0.8973\n",
      "Epoch 19/50\n",
      "173/173 [==============================] - 0s 552us/step - loss: 0.2416 - accuracy: 0.9150 - val_loss: 0.3156 - val_accuracy: 0.8995\n",
      "Epoch 20/50\n",
      "173/173 [==============================] - 0s 555us/step - loss: 0.2422 - accuracy: 0.9158 - val_loss: 0.3160 - val_accuracy: 0.8952\n",
      "Epoch 21/50\n",
      "173/173 [==============================] - 0s 551us/step - loss: 0.2409 - accuracy: 0.9192 - val_loss: 0.3140 - val_accuracy: 0.8995\n",
      "Epoch 22/50\n",
      "173/173 [==============================] - 0s 547us/step - loss: 0.2336 - accuracy: 0.9212 - val_loss: 0.3154 - val_accuracy: 0.9017\n",
      "Epoch 23/50\n",
      "173/173 [==============================] - 0s 549us/step - loss: 0.2309 - accuracy: 0.9228 - val_loss: 0.3155 - val_accuracy: 0.9009\n",
      "Epoch 24/50\n",
      "173/173 [==============================] - 0s 557us/step - loss: 0.2391 - accuracy: 0.9183 - val_loss: 0.3154 - val_accuracy: 0.8988\n",
      "Epoch 25/50\n",
      "173/173 [==============================] - 0s 546us/step - loss: 0.2261 - accuracy: 0.9225 - val_loss: 0.3279 - val_accuracy: 0.9046\n",
      "Epoch 26/50\n",
      "173/173 [==============================] - 0s 542us/step - loss: 0.2287 - accuracy: 0.9235 - val_loss: 0.3167 - val_accuracy: 0.9053\n",
      "Epoch 27/50\n",
      "173/173 [==============================] - 0s 548us/step - loss: 0.2210 - accuracy: 0.9239 - val_loss: 0.3385 - val_accuracy: 0.8980\n",
      "Epoch 28/50\n",
      "173/173 [==============================] - 0s 544us/step - loss: 0.2202 - accuracy: 0.9252 - val_loss: 0.3347 - val_accuracy: 0.9009\n",
      "Epoch 29/50\n",
      "173/173 [==============================] - 0s 541us/step - loss: 0.2229 - accuracy: 0.9257 - val_loss: 0.3240 - val_accuracy: 0.9002\n",
      "Epoch 30/50\n",
      "173/173 [==============================] - 0s 543us/step - loss: 0.2158 - accuracy: 0.9228 - val_loss: 0.3334 - val_accuracy: 0.8980\n",
      "Epoch 31/50\n",
      "173/173 [==============================] - 0s 552us/step - loss: 0.2151 - accuracy: 0.9295 - val_loss: 0.3384 - val_accuracy: 0.9031\n",
      "Epoch 32/50\n",
      "173/173 [==============================] - 0s 549us/step - loss: 0.2109 - accuracy: 0.9281 - val_loss: 0.3340 - val_accuracy: 0.9031\n",
      "Epoch 33/50\n",
      "173/173 [==============================] - 0s 543us/step - loss: 0.2111 - accuracy: 0.9300 - val_loss: 0.3460 - val_accuracy: 0.9017\n",
      "Epoch 34/50\n",
      "173/173 [==============================] - 0s 548us/step - loss: 0.2099 - accuracy: 0.9281 - val_loss: 0.3471 - val_accuracy: 0.9038\n",
      "Epoch 35/50\n",
      "173/173 [==============================] - 0s 585us/step - loss: 0.2110 - accuracy: 0.9284 - val_loss: 0.3439 - val_accuracy: 0.9031\n",
      "Epoch 36/50\n",
      "173/173 [==============================] - 0s 554us/step - loss: 0.2013 - accuracy: 0.9340 - val_loss: 0.3578 - val_accuracy: 0.8966\n",
      "Epoch 37/50\n",
      "173/173 [==============================] - 0s 543us/step - loss: 0.2041 - accuracy: 0.9329 - val_loss: 0.3596 - val_accuracy: 0.9038\n",
      "Epoch 38/50\n",
      "173/173 [==============================] - 0s 543us/step - loss: 0.1943 - accuracy: 0.9317 - val_loss: 0.3597 - val_accuracy: 0.9024\n",
      "Epoch 39/50\n",
      "173/173 [==============================] - 0s 534us/step - loss: 0.1997 - accuracy: 0.9326 - val_loss: 0.3567 - val_accuracy: 0.9017\n",
      "Epoch 40/50\n",
      "173/173 [==============================] - 0s 535us/step - loss: 0.1960 - accuracy: 0.9322 - val_loss: 0.3592 - val_accuracy: 0.8980\n",
      "Epoch 41/50\n",
      "173/173 [==============================] - 0s 533us/step - loss: 0.1912 - accuracy: 0.9331 - val_loss: 0.3879 - val_accuracy: 0.8988\n",
      "Epoch 42/50\n",
      "173/173 [==============================] - 0s 549us/step - loss: 0.1982 - accuracy: 0.9362 - val_loss: 0.3702 - val_accuracy: 0.9002\n",
      "Epoch 43/50\n",
      "173/173 [==============================] - 0s 550us/step - loss: 0.1965 - accuracy: 0.9342 - val_loss: 0.3649 - val_accuracy: 0.9038\n",
      "Epoch 44/50\n",
      "173/173 [==============================] - 0s 549us/step - loss: 0.1946 - accuracy: 0.9356 - val_loss: 0.3599 - val_accuracy: 0.9024\n",
      "Epoch 45/50\n",
      "173/173 [==============================] - 0s 545us/step - loss: 0.1971 - accuracy: 0.9320 - val_loss: 0.3655 - val_accuracy: 0.9038\n",
      "Epoch 46/50\n",
      "173/173 [==============================] - 0s 538us/step - loss: 0.1942 - accuracy: 0.9351 - val_loss: 0.3716 - val_accuracy: 0.9002\n",
      "Epoch 47/50\n",
      "173/173 [==============================] - 0s 539us/step - loss: 0.1959 - accuracy: 0.9346 - val_loss: 0.3864 - val_accuracy: 0.8995\n",
      "Epoch 48/50\n",
      "173/173 [==============================] - 0s 555us/step - loss: 0.1846 - accuracy: 0.9373 - val_loss: 0.3901 - val_accuracy: 0.9024\n",
      "Epoch 49/50\n",
      "173/173 [==============================] - 0s 552us/step - loss: 0.1848 - accuracy: 0.9369 - val_loss: 0.3873 - val_accuracy: 0.9017\n",
      "Epoch 50/50\n",
      "173/173 [==============================] - 0s 561us/step - loss: 0.1863 - accuracy: 0.9369 - val_loss: 0.3877 - val_accuracy: 0.9060\n",
      "44/44 [==============================] - 0s 290us/step\n",
      "Evaluation Metrics for Endpoint 'NR.ER':\n",
      "Precision: 0.9138\n",
      "Recall: 0.2880\n",
      "F1 Score: 0.4380\n",
      "ROC-AUC: 0.7697\n",
      "Confusion Matrix:\n",
      "[[1194    5]\n",
      " [ 131   53]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Ratthew/anaconda3/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "# Example usage for one endpoint\n",
    "endpoint = 'NR.ER'  # endpoint column name\n",
    "process_endpoint(endpoint, df_ordered)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f548433",
   "metadata": {},
   "source": [
    "# increasing the certainty bar experiments\n",
    "\n",
    "With determinator at 0.5:\n",
    "Evaluation Metrics for Endpoint 'NR.ER':\n",
    "Precision: 0.7684\n",
    "Recall: 0.3967\n",
    "F1 Score: 0.5233\n",
    "ROC-AUC: 0.7630\n",
    "Confusion Matrix:\n",
    "[[1177   22]\n",
    " [ 111   73]]\n",
    " \n",
    "@0.55\n",
    "Precision: 0.7711\n",
    "Recall: 0.3478\n",
    "F1 Score: 0.4794\n",
    "ROC-AUC: 0.7704\n",
    "Confusion Matrix:\n",
    "[[1180   19]\n",
    " [ 120   64]]\n",
    " \n",
    "@0.65\n",
    "Precision: 0.8429\n",
    "Recall: 0.3207\n",
    "F1 Score: 0.4646\n",
    "ROC-AUC: 0.7650\n",
    "Confusion Matrix:\n",
    "[[1188   11]\n",
    " [ 125   59]]\n",
    " \n",
    "@0.75\n",
    "Precision: 0.9138\n",
    "Recall: 0.2880\n",
    "F1 Score: 0.4380\n",
    "ROC-AUC: 0.7697\n",
    "Confusion Matrix:\n",
    "[[1194    5]\n",
    " [ 131   53]]\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a899f821",
   "metadata": {},
   "source": [
    "# loop all 12 at a decision threshold of 0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c6eaf379",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing NR.AhR...\n",
      "Epoch 1/50\n",
      "185/185 [==============================] - 0s 862us/step - loss: 0.3502 - accuracy: 0.8644 - val_loss: 0.2625 - val_accuracy: 0.9004\n",
      "Epoch 2/50\n",
      "185/185 [==============================] - 0s 575us/step - loss: 0.2548 - accuracy: 0.8983 - val_loss: 0.2474 - val_accuracy: 0.9024\n",
      "Epoch 3/50\n",
      "185/185 [==============================] - 0s 562us/step - loss: 0.2372 - accuracy: 0.9054 - val_loss: 0.2438 - val_accuracy: 0.9106\n",
      "Epoch 4/50\n",
      "185/185 [==============================] - 0s 559us/step - loss: 0.2256 - accuracy: 0.9051 - val_loss: 0.2435 - val_accuracy: 0.9106\n",
      "Epoch 5/50\n",
      "185/185 [==============================] - 0s 561us/step - loss: 0.2214 - accuracy: 0.9122 - val_loss: 0.2469 - val_accuracy: 0.9119\n",
      "Epoch 6/50\n",
      "185/185 [==============================] - 0s 557us/step - loss: 0.2012 - accuracy: 0.9163 - val_loss: 0.2439 - val_accuracy: 0.9079\n",
      "Epoch 7/50\n",
      "185/185 [==============================] - 0s 570us/step - loss: 0.2051 - accuracy: 0.9168 - val_loss: 0.2417 - val_accuracy: 0.9119\n",
      "Epoch 8/50\n",
      "185/185 [==============================] - 0s 564us/step - loss: 0.1951 - accuracy: 0.9197 - val_loss: 0.2509 - val_accuracy: 0.9112\n",
      "Epoch 9/50\n",
      "185/185 [==============================] - 0s 564us/step - loss: 0.1906 - accuracy: 0.9244 - val_loss: 0.2425 - val_accuracy: 0.9153\n",
      "Epoch 10/50\n",
      "185/185 [==============================] - 0s 552us/step - loss: 0.1904 - accuracy: 0.9229 - val_loss: 0.2386 - val_accuracy: 0.9126\n",
      "Epoch 11/50\n",
      "185/185 [==============================] - 0s 563us/step - loss: 0.1886 - accuracy: 0.9200 - val_loss: 0.2388 - val_accuracy: 0.9201\n",
      "Epoch 12/50\n",
      "185/185 [==============================] - 0s 550us/step - loss: 0.1738 - accuracy: 0.9315 - val_loss: 0.2566 - val_accuracy: 0.9201\n",
      "Epoch 13/50\n",
      "185/185 [==============================] - 0s 558us/step - loss: 0.1781 - accuracy: 0.9270 - val_loss: 0.2494 - val_accuracy: 0.9207\n",
      "Epoch 14/50\n",
      "185/185 [==============================] - 0s 569us/step - loss: 0.1725 - accuracy: 0.9297 - val_loss: 0.2639 - val_accuracy: 0.9194\n",
      "Epoch 15/50\n",
      "185/185 [==============================] - 0s 561us/step - loss: 0.1660 - accuracy: 0.9322 - val_loss: 0.2756 - val_accuracy: 0.9255\n",
      "Epoch 16/50\n",
      "185/185 [==============================] - 0s 554us/step - loss: 0.1601 - accuracy: 0.9370 - val_loss: 0.3051 - val_accuracy: 0.9207\n",
      "Epoch 17/50\n",
      "185/185 [==============================] - 0s 557us/step - loss: 0.1590 - accuracy: 0.9385 - val_loss: 0.2988 - val_accuracy: 0.9214\n",
      "Epoch 18/50\n",
      "185/185 [==============================] - 0s 550us/step - loss: 0.1568 - accuracy: 0.9393 - val_loss: 0.2990 - val_accuracy: 0.9207\n",
      "Epoch 19/50\n",
      "185/185 [==============================] - 0s 560us/step - loss: 0.1546 - accuracy: 0.9398 - val_loss: 0.2981 - val_accuracy: 0.9214\n",
      "Epoch 20/50\n",
      "185/185 [==============================] - 0s 554us/step - loss: 0.1479 - accuracy: 0.9375 - val_loss: 0.3087 - val_accuracy: 0.9194\n",
      "Epoch 21/50\n",
      "185/185 [==============================] - 0s 557us/step - loss: 0.1446 - accuracy: 0.9444 - val_loss: 0.3192 - val_accuracy: 0.9234\n",
      "Epoch 22/50\n",
      "185/185 [==============================] - 0s 572us/step - loss: 0.1443 - accuracy: 0.9441 - val_loss: 0.3150 - val_accuracy: 0.9194\n",
      "Epoch 23/50\n",
      "185/185 [==============================] - 0s 576us/step - loss: 0.1388 - accuracy: 0.9448 - val_loss: 0.3362 - val_accuracy: 0.9262\n",
      "Epoch 24/50\n",
      "185/185 [==============================] - 0s 576us/step - loss: 0.1401 - accuracy: 0.9464 - val_loss: 0.3306 - val_accuracy: 0.9255\n",
      "Epoch 25/50\n",
      "185/185 [==============================] - 0s 572us/step - loss: 0.1391 - accuracy: 0.9451 - val_loss: 0.3167 - val_accuracy: 0.9228\n",
      "Epoch 26/50\n",
      "185/185 [==============================] - 0s 565us/step - loss: 0.1386 - accuracy: 0.9490 - val_loss: 0.3105 - val_accuracy: 0.9194\n",
      "Epoch 27/50\n",
      "185/185 [==============================] - 0s 594us/step - loss: 0.1278 - accuracy: 0.9510 - val_loss: 0.3174 - val_accuracy: 0.9214\n",
      "Epoch 28/50\n",
      "185/185 [==============================] - 0s 576us/step - loss: 0.1280 - accuracy: 0.9490 - val_loss: 0.3260 - val_accuracy: 0.9241\n",
      "Epoch 29/50\n",
      "185/185 [==============================] - 0s 620us/step - loss: 0.1211 - accuracy: 0.9539 - val_loss: 0.4218 - val_accuracy: 0.9221\n",
      "Epoch 30/50\n",
      "185/185 [==============================] - 0s 619us/step - loss: 0.1302 - accuracy: 0.9522 - val_loss: 0.3543 - val_accuracy: 0.9228\n",
      "Epoch 31/50\n",
      "185/185 [==============================] - 0s 596us/step - loss: 0.1204 - accuracy: 0.9571 - val_loss: 0.3639 - val_accuracy: 0.9275\n",
      "Epoch 32/50\n",
      "185/185 [==============================] - 0s 564us/step - loss: 0.1176 - accuracy: 0.9548 - val_loss: 0.3752 - val_accuracy: 0.9248\n",
      "Epoch 33/50\n",
      "185/185 [==============================] - 0s 585us/step - loss: 0.1154 - accuracy: 0.9559 - val_loss: 0.3901 - val_accuracy: 0.9221\n",
      "Epoch 34/50\n",
      "185/185 [==============================] - 0s 628us/step - loss: 0.1191 - accuracy: 0.9554 - val_loss: 0.4338 - val_accuracy: 0.9268\n",
      "Epoch 35/50\n",
      "185/185 [==============================] - 0s 614us/step - loss: 0.1106 - accuracy: 0.9561 - val_loss: 0.4526 - val_accuracy: 0.9234\n",
      "Epoch 36/50\n",
      "185/185 [==============================] - 0s 633us/step - loss: 0.1072 - accuracy: 0.9593 - val_loss: 0.4415 - val_accuracy: 0.9228\n",
      "Epoch 37/50\n",
      "185/185 [==============================] - 0s 612us/step - loss: 0.1092 - accuracy: 0.9553 - val_loss: 0.4460 - val_accuracy: 0.9268\n",
      "Epoch 38/50\n",
      "185/185 [==============================] - 0s 585us/step - loss: 0.1072 - accuracy: 0.9585 - val_loss: 0.4303 - val_accuracy: 0.9234\n",
      "Epoch 39/50\n",
      "185/185 [==============================] - 0s 580us/step - loss: 0.1130 - accuracy: 0.9585 - val_loss: 0.4230 - val_accuracy: 0.9262\n",
      "Epoch 40/50\n",
      "185/185 [==============================] - 0s 612us/step - loss: 0.1070 - accuracy: 0.9600 - val_loss: 0.4214 - val_accuracy: 0.9275\n",
      "Epoch 41/50\n",
      "185/185 [==============================] - 0s 661us/step - loss: 0.1048 - accuracy: 0.9603 - val_loss: 0.4214 - val_accuracy: 0.9241\n",
      "Epoch 42/50\n",
      "185/185 [==============================] - 0s 675us/step - loss: 0.1014 - accuracy: 0.9619 - val_loss: 0.4501 - val_accuracy: 0.9248\n",
      "Epoch 43/50\n",
      "185/185 [==============================] - 0s 703us/step - loss: 0.1026 - accuracy: 0.9612 - val_loss: 0.4366 - val_accuracy: 0.9255\n",
      "Epoch 44/50\n",
      "185/185 [==============================] - 0s 629us/step - loss: 0.0949 - accuracy: 0.9659 - val_loss: 0.4681 - val_accuracy: 0.9282\n",
      "Epoch 45/50\n",
      "185/185 [==============================] - 0s 651us/step - loss: 0.0970 - accuracy: 0.9658 - val_loss: 0.4963 - val_accuracy: 0.9248\n",
      "Epoch 46/50\n",
      "185/185 [==============================] - 0s 559us/step - loss: 0.1052 - accuracy: 0.9598 - val_loss: 0.4686 - val_accuracy: 0.9262\n",
      "Epoch 47/50\n",
      "185/185 [==============================] - 0s 574us/step - loss: 0.0963 - accuracy: 0.9620 - val_loss: 0.5111 - val_accuracy: 0.9275\n",
      "Epoch 48/50\n",
      "185/185 [==============================] - 0s 620us/step - loss: 0.0925 - accuracy: 0.9648 - val_loss: 0.4970 - val_accuracy: 0.9295\n",
      "Epoch 49/50\n",
      "185/185 [==============================] - 0s 634us/step - loss: 0.0882 - accuracy: 0.9654 - val_loss: 0.5158 - val_accuracy: 0.9289\n",
      "Epoch 50/50\n",
      "185/185 [==============================] - 0s 661us/step - loss: 0.0961 - accuracy: 0.9644 - val_loss: 0.5079 - val_accuracy: 0.9289\n",
      "47/47 [==============================] - 0s 351us/step\n",
      "Evaluation Metrics for Endpoint 'NR.AhR':\n",
      "Precision: 0.8710\n",
      "Recall: 0.4655\n",
      "F1 Score: 0.6067\n",
      "ROC-AUC: 0.8961\n",
      "Confusion Matrix:\n",
      "[[1290   12]\n",
      " [  93   81]]\n",
      "Finished processing NR.AhR.\n",
      "\n",
      "Processing NR.AR...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Ratthew/anaconda3/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "208/208 [==============================] - 0s 805us/step - loss: 0.1673 - accuracy: 0.9576 - val_loss: 0.1079 - val_accuracy: 0.9742\n",
      "Epoch 2/50\n",
      "208/208 [==============================] - 0s 646us/step - loss: 0.1269 - accuracy: 0.9702 - val_loss: 0.1075 - val_accuracy: 0.9754\n",
      "Epoch 3/50\n",
      "208/208 [==============================] - 0s 653us/step - loss: 0.1183 - accuracy: 0.9728 - val_loss: 0.1079 - val_accuracy: 0.9748\n",
      "Epoch 4/50\n",
      "208/208 [==============================] - 0s 675us/step - loss: 0.1141 - accuracy: 0.9745 - val_loss: 0.1065 - val_accuracy: 0.9754\n",
      "Epoch 5/50\n",
      "208/208 [==============================] - 0s 652us/step - loss: 0.1048 - accuracy: 0.9755 - val_loss: 0.1068 - val_accuracy: 0.9754\n",
      "Epoch 6/50\n",
      "208/208 [==============================] - 0s 648us/step - loss: 0.0998 - accuracy: 0.9766 - val_loss: 0.1125 - val_accuracy: 0.9748\n",
      "Epoch 7/50\n",
      "208/208 [==============================] - 0s 560us/step - loss: 0.0996 - accuracy: 0.9760 - val_loss: 0.1061 - val_accuracy: 0.9760\n",
      "Epoch 8/50\n",
      "208/208 [==============================] - 0s 635us/step - loss: 0.0961 - accuracy: 0.9758 - val_loss: 0.1092 - val_accuracy: 0.9754\n",
      "Epoch 9/50\n",
      "208/208 [==============================] - 0s 596us/step - loss: 0.0911 - accuracy: 0.9766 - val_loss: 0.1097 - val_accuracy: 0.9766\n",
      "Epoch 10/50\n",
      "208/208 [==============================] - 0s 638us/step - loss: 0.0855 - accuracy: 0.9787 - val_loss: 0.1116 - val_accuracy: 0.9760\n",
      "Epoch 11/50\n",
      "208/208 [==============================] - 0s 549us/step - loss: 0.0815 - accuracy: 0.9799 - val_loss: 0.1216 - val_accuracy: 0.9760\n",
      "Epoch 12/50\n",
      "208/208 [==============================] - 0s 599us/step - loss: 0.0847 - accuracy: 0.9781 - val_loss: 0.1164 - val_accuracy: 0.9760\n",
      "Epoch 13/50\n",
      "208/208 [==============================] - 0s 578us/step - loss: 0.0795 - accuracy: 0.9787 - val_loss: 0.1269 - val_accuracy: 0.9760\n",
      "Epoch 14/50\n",
      "208/208 [==============================] - 0s 569us/step - loss: 0.0800 - accuracy: 0.9799 - val_loss: 0.1225 - val_accuracy: 0.9772\n",
      "Epoch 15/50\n",
      "208/208 [==============================] - 0s 573us/step - loss: 0.0820 - accuracy: 0.9778 - val_loss: 0.1197 - val_accuracy: 0.9760\n",
      "Epoch 16/50\n",
      "208/208 [==============================] - 0s 583us/step - loss: 0.0808 - accuracy: 0.9776 - val_loss: 0.1240 - val_accuracy: 0.9784\n",
      "Epoch 17/50\n",
      "208/208 [==============================] - 0s 565us/step - loss: 0.0750 - accuracy: 0.9793 - val_loss: 0.1313 - val_accuracy: 0.9754\n",
      "Epoch 18/50\n",
      "208/208 [==============================] - 0s 570us/step - loss: 0.0769 - accuracy: 0.9802 - val_loss: 0.1328 - val_accuracy: 0.9760\n",
      "Epoch 19/50\n",
      "208/208 [==============================] - 0s 579us/step - loss: 0.0702 - accuracy: 0.9808 - val_loss: 0.1342 - val_accuracy: 0.9754\n",
      "Epoch 20/50\n",
      "208/208 [==============================] - 0s 582us/step - loss: 0.0719 - accuracy: 0.9803 - val_loss: 0.1360 - val_accuracy: 0.9760\n",
      "Epoch 21/50\n",
      "208/208 [==============================] - 0s 518us/step - loss: 0.0679 - accuracy: 0.9802 - val_loss: 0.1381 - val_accuracy: 0.9760\n",
      "Epoch 22/50\n",
      "208/208 [==============================] - 0s 574us/step - loss: 0.0691 - accuracy: 0.9799 - val_loss: 0.1377 - val_accuracy: 0.9766\n",
      "Epoch 23/50\n",
      "208/208 [==============================] - 0s 570us/step - loss: 0.0699 - accuracy: 0.9794 - val_loss: 0.1470 - val_accuracy: 0.9784\n",
      "Epoch 24/50\n",
      "208/208 [==============================] - 0s 565us/step - loss: 0.0650 - accuracy: 0.9808 - val_loss: 0.1543 - val_accuracy: 0.9772\n",
      "Epoch 25/50\n",
      "208/208 [==============================] - 0s 571us/step - loss: 0.0641 - accuracy: 0.9811 - val_loss: 0.1551 - val_accuracy: 0.9760\n",
      "Epoch 26/50\n",
      "208/208 [==============================] - 0s 579us/step - loss: 0.0651 - accuracy: 0.9818 - val_loss: 0.1541 - val_accuracy: 0.9772\n",
      "Epoch 27/50\n",
      "208/208 [==============================] - 0s 522us/step - loss: 0.0629 - accuracy: 0.9817 - val_loss: 0.1535 - val_accuracy: 0.9772\n",
      "Epoch 28/50\n",
      "208/208 [==============================] - 0s 567us/step - loss: 0.0616 - accuracy: 0.9815 - val_loss: 0.1580 - val_accuracy: 0.9760\n",
      "Epoch 29/50\n",
      "208/208 [==============================] - 0s 551us/step - loss: 0.0582 - accuracy: 0.9827 - val_loss: 0.1612 - val_accuracy: 0.9766\n",
      "Epoch 30/50\n",
      "208/208 [==============================] - 0s 617us/step - loss: 0.0595 - accuracy: 0.9830 - val_loss: 0.1611 - val_accuracy: 0.9778\n",
      "Epoch 31/50\n",
      "208/208 [==============================] - 0s 612us/step - loss: 0.0650 - accuracy: 0.9818 - val_loss: 0.1765 - val_accuracy: 0.9742\n",
      "Epoch 32/50\n",
      "208/208 [==============================] - 0s 569us/step - loss: 0.0603 - accuracy: 0.9827 - val_loss: 0.1692 - val_accuracy: 0.9766\n",
      "Epoch 33/50\n",
      "208/208 [==============================] - 0s 513us/step - loss: 0.0594 - accuracy: 0.9823 - val_loss: 0.1728 - val_accuracy: 0.9766\n",
      "Epoch 34/50\n",
      "208/208 [==============================] - 0s 577us/step - loss: 0.0559 - accuracy: 0.9847 - val_loss: 0.1784 - val_accuracy: 0.9772\n",
      "Epoch 35/50\n",
      "208/208 [==============================] - 0s 655us/step - loss: 0.0553 - accuracy: 0.9824 - val_loss: 0.1850 - val_accuracy: 0.9766\n",
      "Epoch 36/50\n",
      "208/208 [==============================] - 0s 673us/step - loss: 0.0546 - accuracy: 0.9857 - val_loss: 0.2008 - val_accuracy: 0.9766\n",
      "Epoch 37/50\n",
      "208/208 [==============================] - 0s 661us/step - loss: 0.0535 - accuracy: 0.9835 - val_loss: 0.1829 - val_accuracy: 0.9778\n",
      "Epoch 38/50\n",
      "208/208 [==============================] - 0s 564us/step - loss: 0.0516 - accuracy: 0.9839 - val_loss: 0.1925 - val_accuracy: 0.9784\n",
      "Epoch 39/50\n",
      "208/208 [==============================] - 0s 623us/step - loss: 0.0543 - accuracy: 0.9832 - val_loss: 0.1967 - val_accuracy: 0.9754\n",
      "Epoch 40/50\n",
      "208/208 [==============================] - 0s 584us/step - loss: 0.0540 - accuracy: 0.9833 - val_loss: 0.1942 - val_accuracy: 0.9772\n",
      "Epoch 41/50\n",
      "208/208 [==============================] - 0s 667us/step - loss: 0.0518 - accuracy: 0.9848 - val_loss: 0.2095 - val_accuracy: 0.9784\n",
      "Epoch 42/50\n",
      "208/208 [==============================] - 0s 642us/step - loss: 0.0516 - accuracy: 0.9853 - val_loss: 0.1973 - val_accuracy: 0.9778\n",
      "Epoch 43/50\n",
      "208/208 [==============================] - 0s 677us/step - loss: 0.0495 - accuracy: 0.9848 - val_loss: 0.2141 - val_accuracy: 0.9784\n",
      "Epoch 44/50\n",
      "208/208 [==============================] - 0s 610us/step - loss: 0.0482 - accuracy: 0.9833 - val_loss: 0.2253 - val_accuracy: 0.9784\n",
      "Epoch 45/50\n",
      "208/208 [==============================] - 0s 571us/step - loss: 0.0480 - accuracy: 0.9848 - val_loss: 0.2213 - val_accuracy: 0.9778\n",
      "Epoch 46/50\n",
      "208/208 [==============================] - 0s 658us/step - loss: 0.0482 - accuracy: 0.9853 - val_loss: 0.2184 - val_accuracy: 0.9790\n",
      "Epoch 47/50\n",
      "208/208 [==============================] - 0s 626us/step - loss: 0.0471 - accuracy: 0.9856 - val_loss: 0.2127 - val_accuracy: 0.9778\n",
      "Epoch 48/50\n",
      "208/208 [==============================] - 0s 669us/step - loss: 0.0491 - accuracy: 0.9860 - val_loss: 0.2167 - val_accuracy: 0.9784\n",
      "Epoch 49/50\n",
      "208/208 [==============================] - 0s 656us/step - loss: 0.0488 - accuracy: 0.9853 - val_loss: 0.2198 - val_accuracy: 0.9766\n",
      "Epoch 50/50\n",
      "208/208 [==============================] - 0s 642us/step - loss: 0.0456 - accuracy: 0.9856 - val_loss: 0.2205 - val_accuracy: 0.9784\n",
      "52/52 [==============================] - 0s 259us/step\n",
      "Evaluation Metrics for Endpoint 'NR.AR':\n",
      "Precision: 0.8780\n",
      "Recall: 0.5294\n",
      "F1 Score: 0.6606\n",
      "ROC-AUC: 0.8040\n",
      "Confusion Matrix:\n",
      "[[1591    5]\n",
      " [  32   36]]\n",
      "Finished processing NR.AR.\n",
      "\n",
      "Processing NR.AR.LBD...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Ratthew/anaconda3/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "193/193 [==============================] - 0s 915us/step - loss: 0.1745 - accuracy: 0.9474 - val_loss: 0.0970 - val_accuracy: 0.9792\n",
      "Epoch 2/50\n",
      "193/193 [==============================] - 0s 597us/step - loss: 0.1018 - accuracy: 0.9726 - val_loss: 0.0955 - val_accuracy: 0.9773\n",
      "Epoch 3/50\n",
      "193/193 [==============================] - 0s 592us/step - loss: 0.0996 - accuracy: 0.9739 - val_loss: 0.0860 - val_accuracy: 0.9766\n",
      "Epoch 4/50\n",
      "193/193 [==============================] - 0s 602us/step - loss: 0.0929 - accuracy: 0.9750 - val_loss: 0.0856 - val_accuracy: 0.9779\n",
      "Epoch 5/50\n",
      "193/193 [==============================] - 0s 594us/step - loss: 0.0766 - accuracy: 0.9758 - val_loss: 0.0849 - val_accuracy: 0.9773\n",
      "Epoch 6/50\n",
      "193/193 [==============================] - 0s 566us/step - loss: 0.0743 - accuracy: 0.9799 - val_loss: 0.0845 - val_accuracy: 0.9773\n",
      "Epoch 7/50\n",
      "193/193 [==============================] - 0s 583us/step - loss: 0.0704 - accuracy: 0.9792 - val_loss: 0.0846 - val_accuracy: 0.9773\n",
      "Epoch 8/50\n",
      "193/193 [==============================] - 0s 580us/step - loss: 0.0719 - accuracy: 0.9770 - val_loss: 0.0785 - val_accuracy: 0.9779\n",
      "Epoch 9/50\n",
      "193/193 [==============================] - 0s 583us/step - loss: 0.0670 - accuracy: 0.9787 - val_loss: 0.0783 - val_accuracy: 0.9786\n",
      "Epoch 10/50\n",
      "193/193 [==============================] - 0s 619us/step - loss: 0.0667 - accuracy: 0.9800 - val_loss: 0.0792 - val_accuracy: 0.9779\n",
      "Epoch 11/50\n",
      "193/193 [==============================] - 0s 571us/step - loss: 0.0595 - accuracy: 0.9825 - val_loss: 0.0882 - val_accuracy: 0.9786\n",
      "Epoch 12/50\n",
      "193/193 [==============================] - 0s 585us/step - loss: 0.0598 - accuracy: 0.9804 - val_loss: 0.0819 - val_accuracy: 0.9786\n",
      "Epoch 13/50\n",
      "193/193 [==============================] - 0s 657us/step - loss: 0.0580 - accuracy: 0.9820 - val_loss: 0.0897 - val_accuracy: 0.9766\n",
      "Epoch 14/50\n",
      "193/193 [==============================] - 0s 565us/step - loss: 0.0520 - accuracy: 0.9828 - val_loss: 0.0834 - val_accuracy: 0.9799\n",
      "Epoch 15/50\n",
      "193/193 [==============================] - 0s 654us/step - loss: 0.0526 - accuracy: 0.9825 - val_loss: 0.0835 - val_accuracy: 0.9812\n",
      "Epoch 16/50\n",
      "193/193 [==============================] - 0s 671us/step - loss: 0.0508 - accuracy: 0.9809 - val_loss: 0.0890 - val_accuracy: 0.9779\n",
      "Epoch 17/50\n",
      "193/193 [==============================] - 0s 690us/step - loss: 0.0545 - accuracy: 0.9831 - val_loss: 0.0902 - val_accuracy: 0.9825\n",
      "Epoch 18/50\n",
      "193/193 [==============================] - 0s 653us/step - loss: 0.0494 - accuracy: 0.9836 - val_loss: 0.0867 - val_accuracy: 0.9799\n",
      "Epoch 19/50\n",
      "193/193 [==============================] - 0s 586us/step - loss: 0.0502 - accuracy: 0.9830 - val_loss: 0.0873 - val_accuracy: 0.9786\n",
      "Epoch 20/50\n",
      "193/193 [==============================] - 0s 669us/step - loss: 0.0471 - accuracy: 0.9831 - val_loss: 0.0923 - val_accuracy: 0.9812\n",
      "Epoch 21/50\n",
      "193/193 [==============================] - 0s 583us/step - loss: 0.0435 - accuracy: 0.9841 - val_loss: 0.0947 - val_accuracy: 0.9799\n",
      "Epoch 22/50\n",
      "193/193 [==============================] - 0s 685us/step - loss: 0.0451 - accuracy: 0.9833 - val_loss: 0.0948 - val_accuracy: 0.9799\n",
      "Epoch 23/50\n",
      "193/193 [==============================] - 0s 671us/step - loss: 0.0407 - accuracy: 0.9854 - val_loss: 0.0974 - val_accuracy: 0.9805\n",
      "Epoch 24/50\n",
      "193/193 [==============================] - 0s 632us/step - loss: 0.0409 - accuracy: 0.9859 - val_loss: 0.1040 - val_accuracy: 0.9831\n",
      "Epoch 25/50\n",
      "193/193 [==============================] - 0s 642us/step - loss: 0.0430 - accuracy: 0.9846 - val_loss: 0.1088 - val_accuracy: 0.9812\n",
      "Epoch 26/50\n",
      "193/193 [==============================] - 0s 646us/step - loss: 0.0393 - accuracy: 0.9864 - val_loss: 0.1116 - val_accuracy: 0.9779\n",
      "Epoch 27/50\n",
      "193/193 [==============================] - 0s 704us/step - loss: 0.0416 - accuracy: 0.9856 - val_loss: 0.1020 - val_accuracy: 0.9831\n",
      "Epoch 28/50\n",
      "193/193 [==============================] - 0s 698us/step - loss: 0.0342 - accuracy: 0.9885 - val_loss: 0.1183 - val_accuracy: 0.9792\n",
      "Epoch 29/50\n",
      "193/193 [==============================] - 0s 750us/step - loss: 0.0433 - accuracy: 0.9864 - val_loss: 0.1060 - val_accuracy: 0.9831\n",
      "Epoch 30/50\n",
      "193/193 [==============================] - 0s 689us/step - loss: 0.0356 - accuracy: 0.9867 - val_loss: 0.1202 - val_accuracy: 0.9838\n",
      "Epoch 31/50\n",
      "193/193 [==============================] - 0s 636us/step - loss: 0.0343 - accuracy: 0.9890 - val_loss: 0.1251 - val_accuracy: 0.9818\n",
      "Epoch 32/50\n",
      "193/193 [==============================] - 0s 548us/step - loss: 0.0354 - accuracy: 0.9882 - val_loss: 0.1175 - val_accuracy: 0.9805\n",
      "Epoch 33/50\n",
      "193/193 [==============================] - 0s 636us/step - loss: 0.0335 - accuracy: 0.9875 - val_loss: 0.1264 - val_accuracy: 0.9799\n",
      "Epoch 34/50\n",
      "193/193 [==============================] - 0s 639us/step - loss: 0.0339 - accuracy: 0.9895 - val_loss: 0.1287 - val_accuracy: 0.9838\n",
      "Epoch 35/50\n",
      "193/193 [==============================] - 0s 667us/step - loss: 0.0332 - accuracy: 0.9883 - val_loss: 0.1194 - val_accuracy: 0.9825\n",
      "Epoch 36/50\n",
      "193/193 [==============================] - 0s 584us/step - loss: 0.0299 - accuracy: 0.9890 - val_loss: 0.1404 - val_accuracy: 0.9825\n",
      "Epoch 37/50\n",
      "193/193 [==============================] - 0s 588us/step - loss: 0.0314 - accuracy: 0.9899 - val_loss: 0.1328 - val_accuracy: 0.9825\n",
      "Epoch 38/50\n",
      "193/193 [==============================] - 0s 596us/step - loss: 0.0320 - accuracy: 0.9883 - val_loss: 0.1420 - val_accuracy: 0.9812\n",
      "Epoch 39/50\n",
      "193/193 [==============================] - 0s 583us/step - loss: 0.0320 - accuracy: 0.9890 - val_loss: 0.1395 - val_accuracy: 0.9831\n",
      "Epoch 40/50\n",
      "193/193 [==============================] - 0s 606us/step - loss: 0.0297 - accuracy: 0.9888 - val_loss: 0.1413 - val_accuracy: 0.9825\n",
      "Epoch 41/50\n",
      "193/193 [==============================] - 0s 601us/step - loss: 0.0297 - accuracy: 0.9896 - val_loss: 0.1343 - val_accuracy: 0.9825\n",
      "Epoch 42/50\n",
      "193/193 [==============================] - 0s 616us/step - loss: 0.0271 - accuracy: 0.9906 - val_loss: 0.1454 - val_accuracy: 0.9825\n",
      "Epoch 43/50\n",
      "193/193 [==============================] - 0s 614us/step - loss: 0.0284 - accuracy: 0.9896 - val_loss: 0.1527 - val_accuracy: 0.9831\n",
      "Epoch 44/50\n",
      "193/193 [==============================] - 0s 619us/step - loss: 0.0286 - accuracy: 0.9893 - val_loss: 0.1511 - val_accuracy: 0.9825\n",
      "Epoch 45/50\n",
      "193/193 [==============================] - 0s 597us/step - loss: 0.0253 - accuracy: 0.9898 - val_loss: 0.1554 - val_accuracy: 0.9825\n",
      "Epoch 46/50\n",
      "193/193 [==============================] - 0s 612us/step - loss: 0.0271 - accuracy: 0.9911 - val_loss: 0.1588 - val_accuracy: 0.9818\n",
      "Epoch 47/50\n",
      "193/193 [==============================] - 0s 599us/step - loss: 0.0312 - accuracy: 0.9895 - val_loss: 0.1719 - val_accuracy: 0.9799\n",
      "Epoch 48/50\n",
      "193/193 [==============================] - 0s 564us/step - loss: 0.0299 - accuracy: 0.9895 - val_loss: 0.1814 - val_accuracy: 0.9812\n",
      "Epoch 49/50\n",
      "193/193 [==============================] - 0s 752us/step - loss: 0.0222 - accuracy: 0.9911 - val_loss: 0.1785 - val_accuracy: 0.9812\n",
      "Epoch 50/50\n",
      "193/193 [==============================] - 0s 608us/step - loss: 0.0271 - accuracy: 0.9914 - val_loss: 0.1643 - val_accuracy: 0.9838\n",
      "49/49 [==============================] - 0s 285us/step\n",
      "Evaluation Metrics for Endpoint 'NR.AR.LBD':\n",
      "Precision: 0.8444\n",
      "Recall: 0.6786\n",
      "F1 Score: 0.7525\n",
      "ROC-AUC: 0.9106\n",
      "Confusion Matrix:\n",
      "[[1478    7]\n",
      " [  18   38]]\n",
      "Finished processing NR.AR.LBD.\n",
      "\n",
      "Processing NR.Aromatase...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Ratthew/anaconda3/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "162/162 [==============================] - 0s 910us/step - loss: 0.2478 - accuracy: 0.9225 - val_loss: 0.1622 - val_accuracy: 0.9512\n",
      "Epoch 2/50\n",
      "162/162 [==============================] - 0s 622us/step - loss: 0.1780 - accuracy: 0.9458 - val_loss: 0.1472 - val_accuracy: 0.9512\n",
      "Epoch 3/50\n",
      "162/162 [==============================] - 0s 549us/step - loss: 0.1681 - accuracy: 0.9483 - val_loss: 0.1442 - val_accuracy: 0.9574\n",
      "Epoch 4/50\n",
      "162/162 [==============================] - 0s 595us/step - loss: 0.1549 - accuracy: 0.9497 - val_loss: 0.1453 - val_accuracy: 0.9551\n",
      "Epoch 5/50\n",
      "162/162 [==============================] - 0s 609us/step - loss: 0.1465 - accuracy: 0.9541 - val_loss: 0.1454 - val_accuracy: 0.9559\n",
      "Epoch 6/50\n",
      "162/162 [==============================] - 0s 607us/step - loss: 0.1414 - accuracy: 0.9533 - val_loss: 0.1454 - val_accuracy: 0.9574\n",
      "Epoch 7/50\n",
      "162/162 [==============================] - 0s 610us/step - loss: 0.1398 - accuracy: 0.9553 - val_loss: 0.1453 - val_accuracy: 0.9590\n",
      "Epoch 8/50\n",
      "162/162 [==============================] - 0s 597us/step - loss: 0.1297 - accuracy: 0.9566 - val_loss: 0.1507 - val_accuracy: 0.9574\n",
      "Epoch 9/50\n",
      "162/162 [==============================] - 0s 608us/step - loss: 0.1274 - accuracy: 0.9557 - val_loss: 0.1492 - val_accuracy: 0.9574\n",
      "Epoch 10/50\n",
      "162/162 [==============================] - 0s 603us/step - loss: 0.1267 - accuracy: 0.9588 - val_loss: 0.1513 - val_accuracy: 0.9582\n",
      "Epoch 11/50\n",
      "162/162 [==============================] - 0s 615us/step - loss: 0.1151 - accuracy: 0.9599 - val_loss: 0.1497 - val_accuracy: 0.9582\n",
      "Epoch 12/50\n",
      "162/162 [==============================] - 0s 582us/step - loss: 0.1203 - accuracy: 0.9597 - val_loss: 0.1495 - val_accuracy: 0.9590\n",
      "Epoch 13/50\n",
      "162/162 [==============================] - 0s 591us/step - loss: 0.1141 - accuracy: 0.9605 - val_loss: 0.1530 - val_accuracy: 0.9598\n",
      "Epoch 14/50\n",
      "162/162 [==============================] - 0s 602us/step - loss: 0.1098 - accuracy: 0.9630 - val_loss: 0.1588 - val_accuracy: 0.9590\n",
      "Epoch 15/50\n",
      "162/162 [==============================] - 0s 616us/step - loss: 0.1047 - accuracy: 0.9613 - val_loss: 0.1628 - val_accuracy: 0.9598\n",
      "Epoch 16/50\n",
      "162/162 [==============================] - 0s 620us/step - loss: 0.1072 - accuracy: 0.9605 - val_loss: 0.1625 - val_accuracy: 0.9590\n",
      "Epoch 17/50\n",
      "162/162 [==============================] - 0s 608us/step - loss: 0.1093 - accuracy: 0.9615 - val_loss: 0.1635 - val_accuracy: 0.9621\n",
      "Epoch 18/50\n",
      "162/162 [==============================] - 0s 613us/step - loss: 0.1005 - accuracy: 0.9651 - val_loss: 0.1596 - val_accuracy: 0.9628\n",
      "Epoch 19/50\n",
      "162/162 [==============================] - 0s 624us/step - loss: 0.0985 - accuracy: 0.9661 - val_loss: 0.1659 - val_accuracy: 0.9636\n",
      "Epoch 20/50\n",
      "162/162 [==============================] - 0s 633us/step - loss: 0.1002 - accuracy: 0.9663 - val_loss: 0.1698 - val_accuracy: 0.9636\n",
      "Epoch 21/50\n",
      "162/162 [==============================] - 0s 537us/step - loss: 0.0973 - accuracy: 0.9649 - val_loss: 0.1734 - val_accuracy: 0.9628\n",
      "Epoch 22/50\n",
      "162/162 [==============================] - 0s 596us/step - loss: 0.0894 - accuracy: 0.9696 - val_loss: 0.1815 - val_accuracy: 0.9598\n",
      "Epoch 23/50\n",
      "162/162 [==============================] - 0s 623us/step - loss: 0.0946 - accuracy: 0.9677 - val_loss: 0.1856 - val_accuracy: 0.9590\n",
      "Epoch 24/50\n",
      "162/162 [==============================] - 0s 618us/step - loss: 0.0928 - accuracy: 0.9667 - val_loss: 0.1775 - val_accuracy: 0.9644\n",
      "Epoch 25/50\n",
      "162/162 [==============================] - 0s 623us/step - loss: 0.0803 - accuracy: 0.9723 - val_loss: 0.1952 - val_accuracy: 0.9628\n",
      "Epoch 26/50\n",
      "162/162 [==============================] - 0s 621us/step - loss: 0.0798 - accuracy: 0.9708 - val_loss: 0.1917 - val_accuracy: 0.9628\n",
      "Epoch 27/50\n",
      "162/162 [==============================] - 0s 606us/step - loss: 0.0811 - accuracy: 0.9723 - val_loss: 0.1944 - val_accuracy: 0.9644\n",
      "Epoch 28/50\n",
      "162/162 [==============================] - 0s 607us/step - loss: 0.0791 - accuracy: 0.9737 - val_loss: 0.2061 - val_accuracy: 0.9621\n",
      "Epoch 29/50\n",
      "162/162 [==============================] - 0s 600us/step - loss: 0.0818 - accuracy: 0.9706 - val_loss: 0.2088 - val_accuracy: 0.9628\n",
      "Epoch 30/50\n",
      "162/162 [==============================] - 0s 542us/step - loss: 0.0761 - accuracy: 0.9715 - val_loss: 0.2214 - val_accuracy: 0.9598\n",
      "Epoch 31/50\n",
      "162/162 [==============================] - 0s 602us/step - loss: 0.0706 - accuracy: 0.9764 - val_loss: 0.2215 - val_accuracy: 0.9636\n",
      "Epoch 32/50\n",
      "162/162 [==============================] - 0s 621us/step - loss: 0.0730 - accuracy: 0.9739 - val_loss: 0.2292 - val_accuracy: 0.9621\n",
      "Epoch 33/50\n",
      "162/162 [==============================] - 0s 599us/step - loss: 0.0775 - accuracy: 0.9733 - val_loss: 0.2209 - val_accuracy: 0.9613\n",
      "Epoch 34/50\n",
      "162/162 [==============================] - 0s 610us/step - loss: 0.0785 - accuracy: 0.9715 - val_loss: 0.2117 - val_accuracy: 0.9613\n",
      "Epoch 35/50\n",
      "162/162 [==============================] - 0s 618us/step - loss: 0.0766 - accuracy: 0.9727 - val_loss: 0.2169 - val_accuracy: 0.9613\n",
      "Epoch 36/50\n",
      "162/162 [==============================] - 0s 607us/step - loss: 0.0741 - accuracy: 0.9723 - val_loss: 0.2196 - val_accuracy: 0.9621\n",
      "Epoch 37/50\n",
      "162/162 [==============================] - 0s 604us/step - loss: 0.0639 - accuracy: 0.9762 - val_loss: 0.2503 - val_accuracy: 0.9636\n",
      "Epoch 38/50\n",
      "162/162 [==============================] - 0s 603us/step - loss: 0.0608 - accuracy: 0.9770 - val_loss: 0.2564 - val_accuracy: 0.9621\n",
      "Epoch 39/50\n",
      "162/162 [==============================] - 0s 592us/step - loss: 0.0659 - accuracy: 0.9768 - val_loss: 0.2524 - val_accuracy: 0.9628\n",
      "Epoch 40/50\n",
      "162/162 [==============================] - 0s 544us/step - loss: 0.0728 - accuracy: 0.9744 - val_loss: 0.2461 - val_accuracy: 0.9613\n",
      "Epoch 41/50\n",
      "162/162 [==============================] - 0s 608us/step - loss: 0.0633 - accuracy: 0.9773 - val_loss: 0.2509 - val_accuracy: 0.9628\n",
      "Epoch 42/50\n",
      "162/162 [==============================] - 0s 609us/step - loss: 0.0630 - accuracy: 0.9758 - val_loss: 0.2624 - val_accuracy: 0.9644\n",
      "Epoch 43/50\n",
      "162/162 [==============================] - 0s 597us/step - loss: 0.0599 - accuracy: 0.9793 - val_loss: 0.2637 - val_accuracy: 0.9644\n",
      "Epoch 44/50\n",
      "162/162 [==============================] - 0s 840us/step - loss: 0.0618 - accuracy: 0.9773 - val_loss: 0.2743 - val_accuracy: 0.9636\n",
      "Epoch 45/50\n",
      "162/162 [==============================] - 0s 620us/step - loss: 0.0631 - accuracy: 0.9775 - val_loss: 0.2753 - val_accuracy: 0.9628\n",
      "Epoch 46/50\n",
      "162/162 [==============================] - 0s 621us/step - loss: 0.0606 - accuracy: 0.9793 - val_loss: 0.2683 - val_accuracy: 0.9636\n",
      "Epoch 47/50\n",
      "162/162 [==============================] - 0s 629us/step - loss: 0.0604 - accuracy: 0.9812 - val_loss: 0.2753 - val_accuracy: 0.9644\n",
      "Epoch 48/50\n",
      "162/162 [==============================] - 0s 611us/step - loss: 0.0572 - accuracy: 0.9781 - val_loss: 0.2926 - val_accuracy: 0.9636\n",
      "Epoch 49/50\n",
      "162/162 [==============================] - 0s 540us/step - loss: 0.0532 - accuracy: 0.9818 - val_loss: 0.3044 - val_accuracy: 0.9636\n",
      "Epoch 50/50\n",
      "162/162 [==============================] - 0s 597us/step - loss: 0.0523 - accuracy: 0.9789 - val_loss: 0.3151 - val_accuracy: 0.9667\n",
      "41/41 [==============================] - 0s 297us/step\n",
      "Evaluation Metrics for Endpoint 'NR.Aromatase':\n",
      "Precision: 0.8571\n",
      "Recall: 0.4478\n",
      "F1 Score: 0.5882\n",
      "ROC-AUC: 0.8666\n",
      "Confusion Matrix:\n",
      "[[1220    5]\n",
      " [  37   30]]\n",
      "Finished processing NR.Aromatase.\n",
      "\n",
      "Processing NR.ER...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Ratthew/anaconda3/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "173/173 [==============================] - 0s 905us/step - loss: 0.3898 - accuracy: 0.8751 - val_loss: 0.3374 - val_accuracy: 0.8894\n",
      "Epoch 2/50\n",
      "173/173 [==============================] - 0s 603us/step - loss: 0.3311 - accuracy: 0.8858 - val_loss: 0.3283 - val_accuracy: 0.8865\n",
      "Epoch 3/50\n",
      "173/173 [==============================] - 0s 591us/step - loss: 0.3167 - accuracy: 0.8917 - val_loss: 0.3218 - val_accuracy: 0.8908\n",
      "Epoch 4/50\n",
      "173/173 [==============================] - 0s 582us/step - loss: 0.3064 - accuracy: 0.8986 - val_loss: 0.3166 - val_accuracy: 0.8923\n",
      "Epoch 5/50\n",
      "173/173 [==============================] - 0s 588us/step - loss: 0.3018 - accuracy: 0.8971 - val_loss: 0.3091 - val_accuracy: 0.8973\n",
      "Epoch 6/50\n",
      "173/173 [==============================] - 0s 604us/step - loss: 0.2891 - accuracy: 0.9002 - val_loss: 0.3092 - val_accuracy: 0.8944\n",
      "Epoch 7/50\n",
      "173/173 [==============================] - 0s 603us/step - loss: 0.2874 - accuracy: 0.8990 - val_loss: 0.3125 - val_accuracy: 0.8901\n",
      "Epoch 8/50\n",
      "173/173 [==============================] - 0s 605us/step - loss: 0.2777 - accuracy: 0.9062 - val_loss: 0.3059 - val_accuracy: 0.8944\n",
      "Epoch 9/50\n",
      "173/173 [==============================] - 0s 597us/step - loss: 0.2737 - accuracy: 0.9060 - val_loss: 0.3094 - val_accuracy: 0.8959\n",
      "Epoch 10/50\n",
      "173/173 [==============================] - 0s 600us/step - loss: 0.2719 - accuracy: 0.9074 - val_loss: 0.3122 - val_accuracy: 0.8944\n",
      "Epoch 11/50\n",
      "173/173 [==============================] - 0s 585us/step - loss: 0.2698 - accuracy: 0.9098 - val_loss: 0.3066 - val_accuracy: 0.8988\n",
      "Epoch 12/50\n",
      "173/173 [==============================] - 0s 578us/step - loss: 0.2622 - accuracy: 0.9094 - val_loss: 0.3083 - val_accuracy: 0.8973\n",
      "Epoch 13/50\n",
      "173/173 [==============================] - 0s 599us/step - loss: 0.2668 - accuracy: 0.9098 - val_loss: 0.3100 - val_accuracy: 0.8980\n",
      "Epoch 14/50\n",
      "173/173 [==============================] - 0s 605us/step - loss: 0.2576 - accuracy: 0.9107 - val_loss: 0.3052 - val_accuracy: 0.8995\n",
      "Epoch 15/50\n",
      "173/173 [==============================] - 0s 602us/step - loss: 0.2613 - accuracy: 0.9103 - val_loss: 0.3041 - val_accuracy: 0.9017\n",
      "Epoch 16/50\n",
      "173/173 [==============================] - 0s 592us/step - loss: 0.2420 - accuracy: 0.9172 - val_loss: 0.3124 - val_accuracy: 0.8980\n",
      "Epoch 17/50\n",
      "173/173 [==============================] - 0s 615us/step - loss: 0.2517 - accuracy: 0.9161 - val_loss: 0.3132 - val_accuracy: 0.8959\n",
      "Epoch 18/50\n",
      "173/173 [==============================] - 0s 595us/step - loss: 0.2482 - accuracy: 0.9161 - val_loss: 0.3100 - val_accuracy: 0.9009\n",
      "Epoch 19/50\n",
      "173/173 [==============================] - 0s 582us/step - loss: 0.2399 - accuracy: 0.9168 - val_loss: 0.3147 - val_accuracy: 0.9024\n",
      "Epoch 20/50\n",
      "173/173 [==============================] - 0s 578us/step - loss: 0.2377 - accuracy: 0.9208 - val_loss: 0.3120 - val_accuracy: 0.8988\n",
      "Epoch 21/50\n",
      "173/173 [==============================] - 0s 602us/step - loss: 0.2391 - accuracy: 0.9134 - val_loss: 0.3115 - val_accuracy: 0.8995\n",
      "Epoch 22/50\n",
      "173/173 [==============================] - 0s 596us/step - loss: 0.2333 - accuracy: 0.9234 - val_loss: 0.3127 - val_accuracy: 0.9053\n",
      "Epoch 23/50\n",
      "173/173 [==============================] - 0s 600us/step - loss: 0.2379 - accuracy: 0.9199 - val_loss: 0.3062 - val_accuracy: 0.9060\n",
      "Epoch 24/50\n",
      "173/173 [==============================] - 0s 601us/step - loss: 0.2288 - accuracy: 0.9235 - val_loss: 0.3164 - val_accuracy: 0.9002\n",
      "Epoch 25/50\n",
      "173/173 [==============================] - 0s 603us/step - loss: 0.2261 - accuracy: 0.9226 - val_loss: 0.3230 - val_accuracy: 0.9017\n",
      "Epoch 26/50\n",
      "173/173 [==============================] - 0s 605us/step - loss: 0.2282 - accuracy: 0.9199 - val_loss: 0.3229 - val_accuracy: 0.9024\n",
      "Epoch 27/50\n",
      "173/173 [==============================] - 0s 605us/step - loss: 0.2209 - accuracy: 0.9253 - val_loss: 0.3210 - val_accuracy: 0.9038\n",
      "Epoch 28/50\n",
      "173/173 [==============================] - 0s 589us/step - loss: 0.2217 - accuracy: 0.9255 - val_loss: 0.3172 - val_accuracy: 0.9031\n",
      "Epoch 29/50\n",
      "173/173 [==============================] - 0s 610us/step - loss: 0.2155 - accuracy: 0.9266 - val_loss: 0.3193 - val_accuracy: 0.9067\n",
      "Epoch 30/50\n",
      "173/173 [==============================] - 0s 623us/step - loss: 0.2158 - accuracy: 0.9290 - val_loss: 0.3333 - val_accuracy: 0.9009\n",
      "Epoch 31/50\n",
      "173/173 [==============================] - 0s 605us/step - loss: 0.2188 - accuracy: 0.9272 - val_loss: 0.3227 - val_accuracy: 0.9060\n",
      "Epoch 32/50\n",
      "173/173 [==============================] - 0s 603us/step - loss: 0.2129 - accuracy: 0.9272 - val_loss: 0.3231 - val_accuracy: 0.9053\n",
      "Epoch 33/50\n",
      "173/173 [==============================] - 0s 610us/step - loss: 0.2086 - accuracy: 0.9331 - val_loss: 0.3230 - val_accuracy: 0.9082\n",
      "Epoch 34/50\n",
      "173/173 [==============================] - 0s 603us/step - loss: 0.2090 - accuracy: 0.9320 - val_loss: 0.3274 - val_accuracy: 0.9046\n",
      "Epoch 35/50\n",
      "173/173 [==============================] - 0s 566us/step - loss: 0.2114 - accuracy: 0.9299 - val_loss: 0.3257 - val_accuracy: 0.9046\n",
      "Epoch 36/50\n",
      "173/173 [==============================] - 0s 526us/step - loss: 0.2126 - accuracy: 0.9291 - val_loss: 0.3336 - val_accuracy: 0.9060\n",
      "Epoch 37/50\n",
      "173/173 [==============================] - 0s 600us/step - loss: 0.2087 - accuracy: 0.9309 - val_loss: 0.3234 - val_accuracy: 0.9024\n",
      "Epoch 38/50\n",
      "173/173 [==============================] - 0s 617us/step - loss: 0.1975 - accuracy: 0.9342 - val_loss: 0.3320 - val_accuracy: 0.9060\n",
      "Epoch 39/50\n",
      "173/173 [==============================] - 0s 606us/step - loss: 0.2025 - accuracy: 0.9322 - val_loss: 0.3188 - val_accuracy: 0.9118\n",
      "Epoch 40/50\n",
      "173/173 [==============================] - 0s 607us/step - loss: 0.1977 - accuracy: 0.9324 - val_loss: 0.3411 - val_accuracy: 0.9038\n",
      "Epoch 41/50\n",
      "173/173 [==============================] - 0s 606us/step - loss: 0.1959 - accuracy: 0.9322 - val_loss: 0.3313 - val_accuracy: 0.9118\n",
      "Epoch 42/50\n",
      "173/173 [==============================] - 0s 615us/step - loss: 0.1969 - accuracy: 0.9367 - val_loss: 0.3400 - val_accuracy: 0.9082\n",
      "Epoch 43/50\n",
      "173/173 [==============================] - 0s 542us/step - loss: 0.1940 - accuracy: 0.9342 - val_loss: 0.3409 - val_accuracy: 0.9046\n",
      "Epoch 44/50\n",
      "173/173 [==============================] - 0s 603us/step - loss: 0.1919 - accuracy: 0.9385 - val_loss: 0.3341 - val_accuracy: 0.9038\n",
      "Epoch 45/50\n",
      "173/173 [==============================] - 0s 601us/step - loss: 0.1885 - accuracy: 0.9398 - val_loss: 0.3504 - val_accuracy: 0.9024\n",
      "Epoch 46/50\n",
      "173/173 [==============================] - 0s 600us/step - loss: 0.1826 - accuracy: 0.9403 - val_loss: 0.3528 - val_accuracy: 0.9046\n",
      "Epoch 47/50\n",
      "173/173 [==============================] - 0s 598us/step - loss: 0.1862 - accuracy: 0.9396 - val_loss: 0.3635 - val_accuracy: 0.9002\n",
      "Epoch 48/50\n",
      "173/173 [==============================] - 0s 605us/step - loss: 0.1879 - accuracy: 0.9364 - val_loss: 0.3563 - val_accuracy: 0.8995\n",
      "Epoch 49/50\n",
      "173/173 [==============================] - 0s 653us/step - loss: 0.1933 - accuracy: 0.9358 - val_loss: 0.3596 - val_accuracy: 0.9046\n",
      "Epoch 50/50\n",
      "173/173 [==============================] - 0s 610us/step - loss: 0.1819 - accuracy: 0.9398 - val_loss: 0.3856 - val_accuracy: 0.9038\n",
      "44/44 [==============================] - 0s 306us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Ratthew/anaconda3/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Metrics for Endpoint 'NR.ER':\n",
      "Precision: 0.8182\n",
      "Recall: 0.3424\n",
      "F1 Score: 0.4828\n",
      "ROC-AUC: 0.7704\n",
      "Confusion Matrix:\n",
      "[[1185   14]\n",
      " [ 121   63]]\n",
      "Finished processing NR.ER.\n",
      "\n",
      "Processing NR.ER.LBD...\n",
      "Epoch 1/50\n",
      "197/197 [==============================] - 0s 869us/step - loss: 0.2397 - accuracy: 0.9299 - val_loss: 0.1611 - val_accuracy: 0.9561\n",
      "Epoch 2/50\n",
      "197/197 [==============================] - 0s 617us/step - loss: 0.1681 - accuracy: 0.9533 - val_loss: 0.1564 - val_accuracy: 0.9586\n",
      "Epoch 3/50\n",
      "197/197 [==============================] - 0s 606us/step - loss: 0.1558 - accuracy: 0.9545 - val_loss: 0.1555 - val_accuracy: 0.9605\n",
      "Epoch 4/50\n",
      "197/197 [==============================] - 0s 587us/step - loss: 0.1409 - accuracy: 0.9565 - val_loss: 0.1529 - val_accuracy: 0.9605\n",
      "Epoch 5/50\n",
      "197/197 [==============================] - 0s 558us/step - loss: 0.1439 - accuracy: 0.9586 - val_loss: 0.1428 - val_accuracy: 0.9605\n",
      "Epoch 6/50\n",
      "197/197 [==============================] - 0s 601us/step - loss: 0.1295 - accuracy: 0.9627 - val_loss: 0.1473 - val_accuracy: 0.9599\n",
      "Epoch 7/50\n",
      "197/197 [==============================] - 0s 593us/step - loss: 0.1328 - accuracy: 0.9627 - val_loss: 0.1470 - val_accuracy: 0.9599\n",
      "Epoch 8/50\n",
      "197/197 [==============================] - 0s 604us/step - loss: 0.1247 - accuracy: 0.9648 - val_loss: 0.1516 - val_accuracy: 0.9605\n",
      "Epoch 9/50\n",
      "197/197 [==============================] - 0s 610us/step - loss: 0.1184 - accuracy: 0.9661 - val_loss: 0.1515 - val_accuracy: 0.9611\n",
      "Epoch 10/50\n",
      "197/197 [==============================] - 0s 610us/step - loss: 0.1168 - accuracy: 0.9637 - val_loss: 0.1471 - val_accuracy: 0.9605\n",
      "Epoch 11/50\n",
      "197/197 [==============================] - 0s 548us/step - loss: 0.1133 - accuracy: 0.9670 - val_loss: 0.1499 - val_accuracy: 0.9605\n",
      "Epoch 12/50\n",
      "197/197 [==============================] - 0s 597us/step - loss: 0.1140 - accuracy: 0.9653 - val_loss: 0.1552 - val_accuracy: 0.9605\n",
      "Epoch 13/50\n",
      "197/197 [==============================] - 0s 710us/step - loss: 0.1093 - accuracy: 0.9689 - val_loss: 0.1514 - val_accuracy: 0.9605\n",
      "Epoch 14/50\n",
      "197/197 [==============================] - 0s 605us/step - loss: 0.1033 - accuracy: 0.9680 - val_loss: 0.1575 - val_accuracy: 0.9592\n",
      "Epoch 15/50\n",
      "197/197 [==============================] - 0s 615us/step - loss: 0.1073 - accuracy: 0.9670 - val_loss: 0.1537 - val_accuracy: 0.9611\n",
      "Epoch 16/50\n",
      "197/197 [==============================] - 0s 583us/step - loss: 0.1001 - accuracy: 0.9686 - val_loss: 0.1530 - val_accuracy: 0.9624\n",
      "Epoch 17/50\n",
      "197/197 [==============================] - 0s 591us/step - loss: 0.0984 - accuracy: 0.9707 - val_loss: 0.1613 - val_accuracy: 0.9611\n",
      "Epoch 18/50\n",
      "197/197 [==============================] - 0s 541us/step - loss: 0.0945 - accuracy: 0.9701 - val_loss: 0.1688 - val_accuracy: 0.9605\n",
      "Epoch 19/50\n",
      "197/197 [==============================] - 0s 649us/step - loss: 0.0961 - accuracy: 0.9696 - val_loss: 0.1718 - val_accuracy: 0.9592\n",
      "Epoch 20/50\n",
      "197/197 [==============================] - 0s 638us/step - loss: 0.0923 - accuracy: 0.9697 - val_loss: 0.1696 - val_accuracy: 0.9592\n",
      "Epoch 21/50\n",
      "197/197 [==============================] - 0s 589us/step - loss: 0.0929 - accuracy: 0.9717 - val_loss: 0.1738 - val_accuracy: 0.9605\n",
      "Epoch 22/50\n",
      "197/197 [==============================] - 0s 679us/step - loss: 0.0928 - accuracy: 0.9709 - val_loss: 0.1743 - val_accuracy: 0.9618\n",
      "Epoch 23/50\n",
      "197/197 [==============================] - 0s 688us/step - loss: 0.0810 - accuracy: 0.9726 - val_loss: 0.1837 - val_accuracy: 0.9618\n",
      "Epoch 24/50\n",
      "197/197 [==============================] - 0s 653us/step - loss: 0.0807 - accuracy: 0.9728 - val_loss: 0.1867 - val_accuracy: 0.9637\n",
      "Epoch 25/50\n",
      "197/197 [==============================] - 0s 663us/step - loss: 0.0912 - accuracy: 0.9717 - val_loss: 0.1877 - val_accuracy: 0.9618\n",
      "Epoch 26/50\n",
      "197/197 [==============================] - 0s 652us/step - loss: 0.0861 - accuracy: 0.9713 - val_loss: 0.1862 - val_accuracy: 0.9611\n",
      "Epoch 27/50\n",
      "197/197 [==============================] - 0s 593us/step - loss: 0.0846 - accuracy: 0.9715 - val_loss: 0.1992 - val_accuracy: 0.9611\n",
      "Epoch 28/50\n",
      "197/197 [==============================] - 0s 691us/step - loss: 0.0771 - accuracy: 0.9756 - val_loss: 0.1985 - val_accuracy: 0.9624\n",
      "Epoch 29/50\n",
      "197/197 [==============================] - 0s 663us/step - loss: 0.0760 - accuracy: 0.9752 - val_loss: 0.2042 - val_accuracy: 0.9637\n",
      "Epoch 30/50\n",
      "197/197 [==============================] - 0s 674us/step - loss: 0.0776 - accuracy: 0.9747 - val_loss: 0.2081 - val_accuracy: 0.9618\n",
      "Epoch 31/50\n",
      "197/197 [==============================] - 0s 629us/step - loss: 0.0757 - accuracy: 0.9750 - val_loss: 0.2178 - val_accuracy: 0.9631\n",
      "Epoch 32/50\n",
      "197/197 [==============================] - 0s 609us/step - loss: 0.0702 - accuracy: 0.9739 - val_loss: 0.2201 - val_accuracy: 0.9643\n",
      "Epoch 33/50\n",
      "197/197 [==============================] - 0s 674us/step - loss: 0.0712 - accuracy: 0.9748 - val_loss: 0.2293 - val_accuracy: 0.9631\n",
      "Epoch 34/50\n",
      "197/197 [==============================] - 0s 650us/step - loss: 0.0664 - accuracy: 0.9755 - val_loss: 0.2449 - val_accuracy: 0.9650\n",
      "Epoch 35/50\n",
      "197/197 [==============================] - 0s 684us/step - loss: 0.0719 - accuracy: 0.9758 - val_loss: 0.2436 - val_accuracy: 0.9637\n",
      "Epoch 36/50\n",
      "197/197 [==============================] - 0s 696us/step - loss: 0.0698 - accuracy: 0.9744 - val_loss: 0.2626 - val_accuracy: 0.9656\n",
      "Epoch 37/50\n",
      "197/197 [==============================] - 0s 619us/step - loss: 0.0663 - accuracy: 0.9782 - val_loss: 0.2509 - val_accuracy: 0.9643\n",
      "Epoch 38/50\n",
      "197/197 [==============================] - 0s 567us/step - loss: 0.0694 - accuracy: 0.9756 - val_loss: 0.2454 - val_accuracy: 0.9643\n",
      "Epoch 39/50\n",
      "197/197 [==============================] - 0s 653us/step - loss: 0.0637 - accuracy: 0.9766 - val_loss: 0.2666 - val_accuracy: 0.9643\n",
      "Epoch 40/50\n",
      "197/197 [==============================] - 0s 669us/step - loss: 0.0645 - accuracy: 0.9766 - val_loss: 0.2640 - val_accuracy: 0.9637\n",
      "Epoch 41/50\n",
      "197/197 [==============================] - 0s 557us/step - loss: 0.0652 - accuracy: 0.9769 - val_loss: 0.2522 - val_accuracy: 0.9631\n",
      "Epoch 42/50\n",
      "197/197 [==============================] - 0s 604us/step - loss: 0.0641 - accuracy: 0.9788 - val_loss: 0.2633 - val_accuracy: 0.9650\n",
      "Epoch 43/50\n",
      "197/197 [==============================] - 0s 626us/step - loss: 0.0622 - accuracy: 0.9777 - val_loss: 0.2724 - val_accuracy: 0.9656\n",
      "Epoch 44/50\n",
      "197/197 [==============================] - 0s 599us/step - loss: 0.0634 - accuracy: 0.9775 - val_loss: 0.2918 - val_accuracy: 0.9656\n",
      "Epoch 45/50\n",
      "197/197 [==============================] - 0s 639us/step - loss: 0.0614 - accuracy: 0.9785 - val_loss: 0.3009 - val_accuracy: 0.9637\n",
      "Epoch 46/50\n",
      "197/197 [==============================] - 0s 601us/step - loss: 0.0591 - accuracy: 0.9804 - val_loss: 0.3043 - val_accuracy: 0.9637\n",
      "Epoch 47/50\n",
      "197/197 [==============================] - 0s 624us/step - loss: 0.0590 - accuracy: 0.9783 - val_loss: 0.3115 - val_accuracy: 0.9637\n",
      "Epoch 48/50\n",
      "197/197 [==============================] - 0s 632us/step - loss: 0.0641 - accuracy: 0.9775 - val_loss: 0.2932 - val_accuracy: 0.9656\n",
      "Epoch 49/50\n",
      "197/197 [==============================] - 0s 637us/step - loss: 0.0578 - accuracy: 0.9822 - val_loss: 0.3353 - val_accuracy: 0.9650\n",
      "Epoch 50/50\n",
      "197/197 [==============================] - 0s 616us/step - loss: 0.0589 - accuracy: 0.9796 - val_loss: 0.3109 - val_accuracy: 0.9650\n",
      "50/50 [==============================] - 0s 284us/step\n",
      "Evaluation Metrics for Endpoint 'NR.ER.LBD':\n",
      "Precision: 0.8667\n",
      "Recall: 0.3291\n",
      "F1 Score: 0.4771\n",
      "ROC-AUC: 0.8000\n",
      "Confusion Matrix:\n",
      "[[1487    4]\n",
      " [  53   26]]\n",
      "Finished processing NR.ER.LBD.\n",
      "\n",
      "Processing NR.PPAR.gamma...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Ratthew/anaconda3/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "186/186 [==============================] - 0s 883us/step - loss: 0.1661 - accuracy: 0.9634 - val_loss: 0.1218 - val_accuracy: 0.9737\n",
      "Epoch 2/50\n",
      "186/186 [==============================] - 0s 614us/step - loss: 0.1268 - accuracy: 0.9708 - val_loss: 0.1089 - val_accuracy: 0.9737\n",
      "Epoch 3/50\n",
      "186/186 [==============================] - 0s 611us/step - loss: 0.1187 - accuracy: 0.9708 - val_loss: 0.1059 - val_accuracy: 0.9737\n",
      "Epoch 4/50\n",
      "186/186 [==============================] - 0s 592us/step - loss: 0.1069 - accuracy: 0.9720 - val_loss: 0.1007 - val_accuracy: 0.9737\n",
      "Epoch 5/50\n",
      "186/186 [==============================] - 0s 606us/step - loss: 0.0978 - accuracy: 0.9710 - val_loss: 0.1019 - val_accuracy: 0.9737\n",
      "Epoch 6/50\n",
      "186/186 [==============================] - 0s 588us/step - loss: 0.0979 - accuracy: 0.9721 - val_loss: 0.0986 - val_accuracy: 0.9723\n",
      "Epoch 7/50\n",
      "186/186 [==============================] - 0s 590us/step - loss: 0.0934 - accuracy: 0.9703 - val_loss: 0.0985 - val_accuracy: 0.9730\n",
      "Epoch 8/50\n",
      "186/186 [==============================] - 0s 603us/step - loss: 0.0853 - accuracy: 0.9720 - val_loss: 0.0969 - val_accuracy: 0.9750\n",
      "Epoch 9/50\n",
      "186/186 [==============================] - 0s 606us/step - loss: 0.0814 - accuracy: 0.9752 - val_loss: 0.0991 - val_accuracy: 0.9757\n",
      "Epoch 10/50\n",
      "186/186 [==============================] - 0s 598us/step - loss: 0.0771 - accuracy: 0.9716 - val_loss: 0.1004 - val_accuracy: 0.9750\n",
      "Epoch 11/50\n",
      "186/186 [==============================] - 0s 585us/step - loss: 0.0704 - accuracy: 0.9742 - val_loss: 0.1033 - val_accuracy: 0.9757\n",
      "Epoch 12/50\n",
      "186/186 [==============================] - 0s 676us/step - loss: 0.0741 - accuracy: 0.9745 - val_loss: 0.1096 - val_accuracy: 0.9750\n",
      "Epoch 13/50\n",
      "186/186 [==============================] - 0s 541us/step - loss: 0.0735 - accuracy: 0.9737 - val_loss: 0.1018 - val_accuracy: 0.9777\n",
      "Epoch 14/50\n",
      "186/186 [==============================] - 0s 595us/step - loss: 0.0660 - accuracy: 0.9762 - val_loss: 0.1067 - val_accuracy: 0.9777\n",
      "Epoch 15/50\n",
      "186/186 [==============================] - 0s 584us/step - loss: 0.0674 - accuracy: 0.9762 - val_loss: 0.1071 - val_accuracy: 0.9797\n",
      "Epoch 16/50\n",
      "186/186 [==============================] - 0s 679us/step - loss: 0.0622 - accuracy: 0.9784 - val_loss: 0.1088 - val_accuracy: 0.9764\n",
      "Epoch 17/50\n",
      "186/186 [==============================] - 0s 680us/step - loss: 0.0580 - accuracy: 0.9765 - val_loss: 0.1139 - val_accuracy: 0.9791\n",
      "Epoch 18/50\n",
      "186/186 [==============================] - 0s 676us/step - loss: 0.0613 - accuracy: 0.9801 - val_loss: 0.1107 - val_accuracy: 0.9777\n",
      "Epoch 19/50\n",
      "186/186 [==============================] - 0s 768us/step - loss: 0.0567 - accuracy: 0.9784 - val_loss: 0.1248 - val_accuracy: 0.9784\n",
      "Epoch 20/50\n",
      "186/186 [==============================] - 0s 667us/step - loss: 0.0530 - accuracy: 0.9779 - val_loss: 0.1321 - val_accuracy: 0.9764\n",
      "Epoch 21/50\n",
      "186/186 [==============================] - 0s 595us/step - loss: 0.0581 - accuracy: 0.9777 - val_loss: 0.1300 - val_accuracy: 0.9804\n",
      "Epoch 22/50\n",
      "186/186 [==============================] - 0s 610us/step - loss: 0.0517 - accuracy: 0.9814 - val_loss: 0.1376 - val_accuracy: 0.9797\n",
      "Epoch 23/50\n",
      "186/186 [==============================] - 0s 638us/step - loss: 0.0487 - accuracy: 0.9806 - val_loss: 0.1391 - val_accuracy: 0.9797\n",
      "Epoch 24/50\n",
      "186/186 [==============================] - 0s 680us/step - loss: 0.0518 - accuracy: 0.9828 - val_loss: 0.1456 - val_accuracy: 0.9784\n",
      "Epoch 25/50\n",
      "186/186 [==============================] - 0s 662us/step - loss: 0.0475 - accuracy: 0.9826 - val_loss: 0.1499 - val_accuracy: 0.9791\n",
      "Epoch 26/50\n",
      "186/186 [==============================] - 0s 657us/step - loss: 0.0510 - accuracy: 0.9804 - val_loss: 0.1513 - val_accuracy: 0.9777\n",
      "Epoch 27/50\n",
      "186/186 [==============================] - 0s 635us/step - loss: 0.0380 - accuracy: 0.9863 - val_loss: 0.1689 - val_accuracy: 0.9797\n",
      "Epoch 28/50\n",
      "186/186 [==============================] - 0s 541us/step - loss: 0.0467 - accuracy: 0.9819 - val_loss: 0.1617 - val_accuracy: 0.9804\n",
      "Epoch 29/50\n",
      "186/186 [==============================] - 0s 598us/step - loss: 0.0412 - accuracy: 0.9840 - val_loss: 0.1656 - val_accuracy: 0.9770\n",
      "Epoch 30/50\n",
      "186/186 [==============================] - 0s 681us/step - loss: 0.0462 - accuracy: 0.9828 - val_loss: 0.1637 - val_accuracy: 0.9764\n",
      "Epoch 31/50\n",
      "186/186 [==============================] - 0s 674us/step - loss: 0.0381 - accuracy: 0.9865 - val_loss: 0.1845 - val_accuracy: 0.9770\n",
      "Epoch 32/50\n",
      "186/186 [==============================] - 0s 684us/step - loss: 0.0435 - accuracy: 0.9840 - val_loss: 0.1727 - val_accuracy: 0.9791\n",
      "Epoch 33/50\n",
      "186/186 [==============================] - 0s 619us/step - loss: 0.0401 - accuracy: 0.9851 - val_loss: 0.1839 - val_accuracy: 0.9791\n",
      "Epoch 34/50\n",
      "186/186 [==============================] - 0s 674us/step - loss: 0.0361 - accuracy: 0.9867 - val_loss: 0.1957 - val_accuracy: 0.9804\n",
      "Epoch 35/50\n",
      "186/186 [==============================] - 0s 602us/step - loss: 0.0362 - accuracy: 0.9865 - val_loss: 0.1990 - val_accuracy: 0.9818\n",
      "Epoch 36/50\n",
      "186/186 [==============================] - 0s 623us/step - loss: 0.0392 - accuracy: 0.9855 - val_loss: 0.2013 - val_accuracy: 0.9777\n",
      "Epoch 37/50\n",
      "186/186 [==============================] - 0s 652us/step - loss: 0.0368 - accuracy: 0.9875 - val_loss: 0.2102 - val_accuracy: 0.9797\n",
      "Epoch 38/50\n",
      "186/186 [==============================] - 0s 623us/step - loss: 0.0382 - accuracy: 0.9867 - val_loss: 0.2221 - val_accuracy: 0.9784\n",
      "Epoch 39/50\n",
      "186/186 [==============================] - 0s 601us/step - loss: 0.0361 - accuracy: 0.9856 - val_loss: 0.2125 - val_accuracy: 0.9791\n",
      "Epoch 40/50\n",
      "186/186 [==============================] - 0s 552us/step - loss: 0.0401 - accuracy: 0.9882 - val_loss: 0.2058 - val_accuracy: 0.9777\n",
      "Epoch 41/50\n",
      "186/186 [==============================] - 0s 602us/step - loss: 0.0316 - accuracy: 0.9880 - val_loss: 0.2328 - val_accuracy: 0.9791\n",
      "Epoch 42/50\n",
      "186/186 [==============================] - 0s 595us/step - loss: 0.0286 - accuracy: 0.9894 - val_loss: 0.2360 - val_accuracy: 0.9804\n",
      "Epoch 43/50\n",
      "186/186 [==============================] - 0s 583us/step - loss: 0.0291 - accuracy: 0.9907 - val_loss: 0.2389 - val_accuracy: 0.9777\n",
      "Epoch 44/50\n",
      "186/186 [==============================] - 0s 542us/step - loss: 0.0322 - accuracy: 0.9878 - val_loss: 0.2468 - val_accuracy: 0.9818\n",
      "Epoch 45/50\n",
      "186/186 [==============================] - 0s 544us/step - loss: 0.0356 - accuracy: 0.9894 - val_loss: 0.2360 - val_accuracy: 0.9804\n",
      "Epoch 46/50\n",
      "186/186 [==============================] - 0s 601us/step - loss: 0.0333 - accuracy: 0.9884 - val_loss: 0.2527 - val_accuracy: 0.9818\n",
      "Epoch 47/50\n",
      "186/186 [==============================] - 0s 586us/step - loss: 0.0269 - accuracy: 0.9904 - val_loss: 0.2875 - val_accuracy: 0.9804\n",
      "Epoch 48/50\n",
      "186/186 [==============================] - 0s 604us/step - loss: 0.0346 - accuracy: 0.9884 - val_loss: 0.2709 - val_accuracy: 0.9804\n",
      "Epoch 49/50\n",
      "186/186 [==============================] - 0s 620us/step - loss: 0.0275 - accuracy: 0.9895 - val_loss: 0.2735 - val_accuracy: 0.9777\n",
      "Epoch 50/50\n",
      "186/186 [==============================] - 0s 586us/step - loss: 0.0336 - accuracy: 0.9887 - val_loss: 0.2752 - val_accuracy: 0.9797\n",
      "47/47 [==============================] - 0s 261us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Ratthew/anaconda3/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Metrics for Endpoint 'NR.PPAR.gamma':\n",
      "Precision: 0.9231\n",
      "Recall: 0.3077\n",
      "F1 Score: 0.4615\n",
      "ROC-AUC: 0.8018\n",
      "Confusion Matrix:\n",
      "[[1441    1]\n",
      " [  27   12]]\n",
      "Finished processing NR.PPAR.gamma.\n",
      "\n",
      "Processing SR.ARE...\n",
      "Epoch 1/50\n",
      "165/165 [==============================] - 0s 893us/step - loss: 0.5249 - accuracy: 0.8021 - val_loss: 0.3701 - val_accuracy: 0.8440\n",
      "Epoch 2/50\n",
      "165/165 [==============================] - 0s 639us/step - loss: 0.4121 - accuracy: 0.8413 - val_loss: 0.3529 - val_accuracy: 0.8508\n",
      "Epoch 3/50\n",
      "165/165 [==============================] - 0s 688us/step - loss: 0.3719 - accuracy: 0.8474 - val_loss: 0.3475 - val_accuracy: 0.8577\n",
      "Epoch 4/50\n",
      "165/165 [==============================] - 0s 688us/step - loss: 0.3515 - accuracy: 0.8605 - val_loss: 0.3389 - val_accuracy: 0.8516\n",
      "Epoch 5/50\n",
      "165/165 [==============================] - 0s 674us/step - loss: 0.3415 - accuracy: 0.8643 - val_loss: 0.3422 - val_accuracy: 0.8562\n",
      "Epoch 6/50\n",
      "165/165 [==============================] - 0s 671us/step - loss: 0.3283 - accuracy: 0.8683 - val_loss: 0.3408 - val_accuracy: 0.8638\n",
      "Epoch 7/50\n",
      "165/165 [==============================] - 0s 621us/step - loss: 0.3202 - accuracy: 0.8725 - val_loss: 0.3380 - val_accuracy: 0.8615\n",
      "Epoch 8/50\n",
      "165/165 [==============================] - 0s 662us/step - loss: 0.3145 - accuracy: 0.8748 - val_loss: 0.3373 - val_accuracy: 0.8569\n",
      "Epoch 9/50\n",
      "165/165 [==============================] - 0s 606us/step - loss: 0.3055 - accuracy: 0.8736 - val_loss: 0.3332 - val_accuracy: 0.8661\n",
      "Epoch 10/50\n",
      "165/165 [==============================] - 0s 691us/step - loss: 0.3074 - accuracy: 0.8733 - val_loss: 0.3349 - val_accuracy: 0.8638\n",
      "Epoch 11/50\n",
      "165/165 [==============================] - 0s 676us/step - loss: 0.3000 - accuracy: 0.8763 - val_loss: 0.3387 - val_accuracy: 0.8653\n",
      "Epoch 12/50\n",
      "165/165 [==============================] - 0s 655us/step - loss: 0.2921 - accuracy: 0.8807 - val_loss: 0.3360 - val_accuracy: 0.8638\n",
      "Epoch 13/50\n",
      "165/165 [==============================] - 0s 536us/step - loss: 0.2848 - accuracy: 0.8854 - val_loss: 0.3430 - val_accuracy: 0.8623\n",
      "Epoch 14/50\n",
      "165/165 [==============================] - 0s 556us/step - loss: 0.2749 - accuracy: 0.8919 - val_loss: 0.3349 - val_accuracy: 0.8615\n",
      "Epoch 15/50\n",
      "165/165 [==============================] - 0s 658us/step - loss: 0.2828 - accuracy: 0.8856 - val_loss: 0.3337 - val_accuracy: 0.8592\n",
      "Epoch 16/50\n",
      "165/165 [==============================] - 0s 662us/step - loss: 0.2806 - accuracy: 0.8889 - val_loss: 0.3375 - val_accuracy: 0.8645\n",
      "Epoch 17/50\n",
      "165/165 [==============================] - 0s 628us/step - loss: 0.2761 - accuracy: 0.8900 - val_loss: 0.3405 - val_accuracy: 0.8623\n",
      "Epoch 18/50\n",
      "165/165 [==============================] - 0s 675us/step - loss: 0.2649 - accuracy: 0.8972 - val_loss: 0.3431 - val_accuracy: 0.8630\n",
      "Epoch 19/50\n",
      "165/165 [==============================] - 0s 676us/step - loss: 0.2652 - accuracy: 0.8967 - val_loss: 0.3462 - val_accuracy: 0.8584\n",
      "Epoch 20/50\n",
      "165/165 [==============================] - 0s 687us/step - loss: 0.2610 - accuracy: 0.8988 - val_loss: 0.3441 - val_accuracy: 0.8630\n",
      "Epoch 21/50\n",
      "165/165 [==============================] - 0s 657us/step - loss: 0.2578 - accuracy: 0.8980 - val_loss: 0.3429 - val_accuracy: 0.8623\n",
      "Epoch 22/50\n",
      "165/165 [==============================] - 0s 684us/step - loss: 0.2537 - accuracy: 0.9001 - val_loss: 0.3712 - val_accuracy: 0.8645\n",
      "Epoch 23/50\n",
      "165/165 [==============================] - 0s 633us/step - loss: 0.2542 - accuracy: 0.8976 - val_loss: 0.3672 - val_accuracy: 0.8653\n",
      "Epoch 24/50\n",
      "165/165 [==============================] - 0s 660us/step - loss: 0.2528 - accuracy: 0.9010 - val_loss: 0.3717 - val_accuracy: 0.8691\n",
      "Epoch 25/50\n",
      "165/165 [==============================] - 0s 613us/step - loss: 0.2413 - accuracy: 0.9050 - val_loss: 0.3768 - val_accuracy: 0.8706\n",
      "Epoch 26/50\n",
      "165/165 [==============================] - 0s 678us/step - loss: 0.2455 - accuracy: 0.9033 - val_loss: 0.3673 - val_accuracy: 0.8699\n",
      "Epoch 27/50\n",
      "165/165 [==============================] - 0s 610us/step - loss: 0.2388 - accuracy: 0.9102 - val_loss: 0.3786 - val_accuracy: 0.8721\n",
      "Epoch 28/50\n",
      "165/165 [==============================] - 0s 595us/step - loss: 0.2286 - accuracy: 0.9104 - val_loss: 0.4044 - val_accuracy: 0.8699\n",
      "Epoch 29/50\n",
      "165/165 [==============================] - 0s 590us/step - loss: 0.2382 - accuracy: 0.9085 - val_loss: 0.3720 - val_accuracy: 0.8691\n",
      "Epoch 30/50\n",
      "165/165 [==============================] - 0s 606us/step - loss: 0.2312 - accuracy: 0.9165 - val_loss: 0.3983 - val_accuracy: 0.8661\n",
      "Epoch 31/50\n",
      "165/165 [==============================] - 0s 554us/step - loss: 0.2205 - accuracy: 0.9159 - val_loss: 0.4118 - val_accuracy: 0.8676\n",
      "Epoch 32/50\n",
      "165/165 [==============================] - 0s 583us/step - loss: 0.2275 - accuracy: 0.9108 - val_loss: 0.4166 - val_accuracy: 0.8676\n",
      "Epoch 33/50\n",
      "165/165 [==============================] - 0s 607us/step - loss: 0.2236 - accuracy: 0.9172 - val_loss: 0.3940 - val_accuracy: 0.8668\n",
      "Epoch 34/50\n",
      "165/165 [==============================] - 0s 608us/step - loss: 0.2237 - accuracy: 0.9161 - val_loss: 0.3933 - val_accuracy: 0.8645\n",
      "Epoch 35/50\n",
      "165/165 [==============================] - 0s 595us/step - loss: 0.2207 - accuracy: 0.9163 - val_loss: 0.3882 - val_accuracy: 0.8714\n",
      "Epoch 36/50\n",
      "165/165 [==============================] - 0s 643us/step - loss: 0.2088 - accuracy: 0.9208 - val_loss: 0.3922 - val_accuracy: 0.8737\n",
      "Epoch 37/50\n",
      "165/165 [==============================] - 0s 590us/step - loss: 0.2151 - accuracy: 0.9180 - val_loss: 0.4119 - val_accuracy: 0.8699\n",
      "Epoch 38/50\n",
      "165/165 [==============================] - 0s 558us/step - loss: 0.2177 - accuracy: 0.9193 - val_loss: 0.4150 - val_accuracy: 0.8699\n",
      "Epoch 39/50\n",
      "165/165 [==============================] - 0s 589us/step - loss: 0.2050 - accuracy: 0.9222 - val_loss: 0.4355 - val_accuracy: 0.8744\n",
      "Epoch 40/50\n",
      "165/165 [==============================] - 0s 612us/step - loss: 0.2003 - accuracy: 0.9260 - val_loss: 0.4300 - val_accuracy: 0.8767\n",
      "Epoch 41/50\n",
      "165/165 [==============================] - 0s 681us/step - loss: 0.2041 - accuracy: 0.9243 - val_loss: 0.4245 - val_accuracy: 0.8744\n",
      "Epoch 42/50\n",
      "165/165 [==============================] - 0s 599us/step - loss: 0.2014 - accuracy: 0.9233 - val_loss: 0.4209 - val_accuracy: 0.8760\n",
      "Epoch 43/50\n",
      "165/165 [==============================] - 0s 646us/step - loss: 0.1989 - accuracy: 0.9250 - val_loss: 0.4454 - val_accuracy: 0.8744\n",
      "Epoch 44/50\n",
      "165/165 [==============================] - 0s 659us/step - loss: 0.1991 - accuracy: 0.9296 - val_loss: 0.4541 - val_accuracy: 0.8767\n",
      "Epoch 45/50\n",
      "165/165 [==============================] - 0s 741us/step - loss: 0.1932 - accuracy: 0.9294 - val_loss: 0.4344 - val_accuracy: 0.8790\n",
      "Epoch 46/50\n",
      "165/165 [==============================] - 0s 693us/step - loss: 0.1946 - accuracy: 0.9284 - val_loss: 0.4303 - val_accuracy: 0.8721\n",
      "Epoch 47/50\n",
      "165/165 [==============================] - 0s 884us/step - loss: 0.1824 - accuracy: 0.9304 - val_loss: 0.4501 - val_accuracy: 0.8790\n",
      "Epoch 48/50\n",
      "165/165 [==============================] - 0s 704us/step - loss: 0.1848 - accuracy: 0.9338 - val_loss: 0.4503 - val_accuracy: 0.8760\n",
      "Epoch 49/50\n",
      "165/165 [==============================] - 0s 648us/step - loss: 0.1958 - accuracy: 0.9319 - val_loss: 0.4714 - val_accuracy: 0.8775\n",
      "Epoch 50/50\n",
      "165/165 [==============================] - 0s 640us/step - loss: 0.1855 - accuracy: 0.9345 - val_loss: 0.4797 - val_accuracy: 0.8706\n",
      "42/42 [==============================] - 0s 365us/step\n",
      "Evaluation Metrics for Endpoint 'SR.ARE':\n",
      "Precision: 0.7297\n",
      "Recall: 0.2596\n",
      "F1 Score: 0.3830\n",
      "ROC-AUC: 0.8303\n",
      "Confusion Matrix:\n",
      "[[1086   20]\n",
      " [ 154   54]]\n",
      "Finished processing SR.ARE.\n",
      "\n",
      "Processing SR.ATAD5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Ratthew/anaconda3/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "205/205 [==============================] - 0s 940us/step - loss: 0.2320 - accuracy: 0.9470 - val_loss: 0.1708 - val_accuracy: 0.9511\n",
      "Epoch 2/50\n",
      "205/205 [==============================] - 0s 651us/step - loss: 0.1629 - accuracy: 0.9601 - val_loss: 0.1533 - val_accuracy: 0.9511\n",
      "Epoch 3/50\n",
      "205/205 [==============================] - 0s 695us/step - loss: 0.1432 - accuracy: 0.9601 - val_loss: 0.1500 - val_accuracy: 0.9511\n",
      "Epoch 4/50\n",
      "205/205 [==============================] - 0s 675us/step - loss: 0.1374 - accuracy: 0.9609 - val_loss: 0.1413 - val_accuracy: 0.9523\n",
      "Epoch 5/50\n",
      "205/205 [==============================] - 0s 681us/step - loss: 0.1283 - accuracy: 0.9615 - val_loss: 0.1472 - val_accuracy: 0.9511\n",
      "Epoch 6/50\n",
      "205/205 [==============================] - 0s 678us/step - loss: 0.1247 - accuracy: 0.9616 - val_loss: 0.1406 - val_accuracy: 0.9517\n",
      "Epoch 7/50\n",
      "205/205 [==============================] - 0s 650us/step - loss: 0.1226 - accuracy: 0.9618 - val_loss: 0.1392 - val_accuracy: 0.9523\n",
      "Epoch 8/50\n",
      "205/205 [==============================] - 0s 620us/step - loss: 0.1149 - accuracy: 0.9630 - val_loss: 0.1375 - val_accuracy: 0.9523\n",
      "Epoch 9/50\n",
      "205/205 [==============================] - 0s 670us/step - loss: 0.1083 - accuracy: 0.9636 - val_loss: 0.1408 - val_accuracy: 0.9535\n",
      "Epoch 10/50\n",
      "205/205 [==============================] - 0s 554us/step - loss: 0.1114 - accuracy: 0.9635 - val_loss: 0.1422 - val_accuracy: 0.9535\n",
      "Epoch 11/50\n",
      "205/205 [==============================] - 0s 569us/step - loss: 0.1034 - accuracy: 0.9652 - val_loss: 0.1360 - val_accuracy: 0.9560\n",
      "Epoch 12/50\n",
      "205/205 [==============================] - 0s 617us/step - loss: 0.0999 - accuracy: 0.9642 - val_loss: 0.1369 - val_accuracy: 0.9554\n",
      "Epoch 13/50\n",
      "205/205 [==============================] - 0s 533us/step - loss: 0.0936 - accuracy: 0.9652 - val_loss: 0.1532 - val_accuracy: 0.9535\n",
      "Epoch 14/50\n",
      "205/205 [==============================] - 0s 599us/step - loss: 0.0907 - accuracy: 0.9664 - val_loss: 0.1460 - val_accuracy: 0.9578\n",
      "Epoch 15/50\n",
      "205/205 [==============================] - 0s 586us/step - loss: 0.0925 - accuracy: 0.9685 - val_loss: 0.1492 - val_accuracy: 0.9566\n",
      "Epoch 16/50\n",
      "205/205 [==============================] - 0s 605us/step - loss: 0.0875 - accuracy: 0.9710 - val_loss: 0.1454 - val_accuracy: 0.9560\n",
      "Epoch 17/50\n",
      "205/205 [==============================] - 0s 599us/step - loss: 0.0911 - accuracy: 0.9690 - val_loss: 0.1423 - val_accuracy: 0.9590\n",
      "Epoch 18/50\n",
      "205/205 [==============================] - 0s 574us/step - loss: 0.0820 - accuracy: 0.9710 - val_loss: 0.1474 - val_accuracy: 0.9621\n",
      "Epoch 19/50\n",
      "205/205 [==============================] - 0s 573us/step - loss: 0.0841 - accuracy: 0.9713 - val_loss: 0.1520 - val_accuracy: 0.9597\n",
      "Epoch 20/50\n",
      "205/205 [==============================] - 0s 588us/step - loss: 0.0755 - accuracy: 0.9725 - val_loss: 0.1623 - val_accuracy: 0.9633\n",
      "Epoch 21/50\n",
      "205/205 [==============================] - 0s 603us/step - loss: 0.0834 - accuracy: 0.9693 - val_loss: 0.1477 - val_accuracy: 0.9639\n",
      "Epoch 22/50\n",
      "205/205 [==============================] - 0s 589us/step - loss: 0.0761 - accuracy: 0.9726 - val_loss: 0.1603 - val_accuracy: 0.9633\n",
      "Epoch 23/50\n",
      "205/205 [==============================] - 0s 679us/step - loss: 0.0798 - accuracy: 0.9730 - val_loss: 0.1559 - val_accuracy: 0.9633\n",
      "Epoch 24/50\n",
      "205/205 [==============================] - 0s 532us/step - loss: 0.0750 - accuracy: 0.9726 - val_loss: 0.1540 - val_accuracy: 0.9645\n",
      "Epoch 25/50\n",
      "205/205 [==============================] - 0s 570us/step - loss: 0.0746 - accuracy: 0.9749 - val_loss: 0.1698 - val_accuracy: 0.9627\n",
      "Epoch 26/50\n",
      "205/205 [==============================] - 0s 607us/step - loss: 0.0679 - accuracy: 0.9736 - val_loss: 0.1761 - val_accuracy: 0.9658\n",
      "Epoch 27/50\n",
      "205/205 [==============================] - 0s 668us/step - loss: 0.0695 - accuracy: 0.9749 - val_loss: 0.1762 - val_accuracy: 0.9615\n",
      "Epoch 28/50\n",
      "205/205 [==============================] - 0s 680us/step - loss: 0.0663 - accuracy: 0.9760 - val_loss: 0.1741 - val_accuracy: 0.9627\n",
      "Epoch 29/50\n",
      "205/205 [==============================] - 0s 665us/step - loss: 0.0594 - accuracy: 0.9775 - val_loss: 0.1847 - val_accuracy: 0.9627\n",
      "Epoch 30/50\n",
      "205/205 [==============================] - 0s 643us/step - loss: 0.0656 - accuracy: 0.9780 - val_loss: 0.1835 - val_accuracy: 0.9627\n",
      "Epoch 31/50\n",
      "205/205 [==============================] - 0s 590us/step - loss: 0.0627 - accuracy: 0.9775 - val_loss: 0.1938 - val_accuracy: 0.9615\n",
      "Epoch 32/50\n",
      "205/205 [==============================] - 0s 679us/step - loss: 0.0559 - accuracy: 0.9788 - val_loss: 0.2139 - val_accuracy: 0.9639\n",
      "Epoch 33/50\n",
      "205/205 [==============================] - 0s 662us/step - loss: 0.0610 - accuracy: 0.9771 - val_loss: 0.2086 - val_accuracy: 0.9621\n",
      "Epoch 34/50\n",
      "205/205 [==============================] - 0s 681us/step - loss: 0.0594 - accuracy: 0.9774 - val_loss: 0.2021 - val_accuracy: 0.9633\n",
      "Epoch 35/50\n",
      "205/205 [==============================] - 0s 657us/step - loss: 0.0596 - accuracy: 0.9780 - val_loss: 0.2075 - val_accuracy: 0.9633\n",
      "Epoch 36/50\n",
      "205/205 [==============================] - 0s 573us/step - loss: 0.0553 - accuracy: 0.9804 - val_loss: 0.2119 - val_accuracy: 0.9621\n",
      "Epoch 37/50\n",
      "205/205 [==============================] - 0s 609us/step - loss: 0.0558 - accuracy: 0.9804 - val_loss: 0.2177 - val_accuracy: 0.9652\n",
      "Epoch 38/50\n",
      "205/205 [==============================] - 0s 697us/step - loss: 0.0569 - accuracy: 0.9798 - val_loss: 0.2252 - val_accuracy: 0.9645\n",
      "Epoch 39/50\n",
      "205/205 [==============================] - 0s 709us/step - loss: 0.0576 - accuracy: 0.9807 - val_loss: 0.2199 - val_accuracy: 0.9658\n",
      "Epoch 40/50\n",
      "205/205 [==============================] - 0s 676us/step - loss: 0.0587 - accuracy: 0.9791 - val_loss: 0.2166 - val_accuracy: 0.9652\n",
      "Epoch 41/50\n",
      "205/205 [==============================] - 0s 606us/step - loss: 0.0501 - accuracy: 0.9803 - val_loss: 0.2234 - val_accuracy: 0.9633\n",
      "Epoch 42/50\n",
      "205/205 [==============================] - 0s 599us/step - loss: 0.0470 - accuracy: 0.9817 - val_loss: 0.2476 - val_accuracy: 0.9645\n",
      "Epoch 43/50\n",
      "205/205 [==============================] - 0s 654us/step - loss: 0.0477 - accuracy: 0.9829 - val_loss: 0.2652 - val_accuracy: 0.9652\n",
      "Epoch 44/50\n",
      "205/205 [==============================] - 0s 662us/step - loss: 0.0447 - accuracy: 0.9843 - val_loss: 0.2590 - val_accuracy: 0.9652\n",
      "Epoch 45/50\n",
      "205/205 [==============================] - 0s 673us/step - loss: 0.0455 - accuracy: 0.9832 - val_loss: 0.2697 - val_accuracy: 0.9639\n",
      "Epoch 46/50\n",
      "205/205 [==============================] - 0s 545us/step - loss: 0.0499 - accuracy: 0.9818 - val_loss: 0.2539 - val_accuracy: 0.9639\n",
      "Epoch 47/50\n",
      "205/205 [==============================] - 0s 613us/step - loss: 0.0444 - accuracy: 0.9844 - val_loss: 0.2297 - val_accuracy: 0.9670\n",
      "Epoch 48/50\n",
      "205/205 [==============================] - 0s 609us/step - loss: 0.0473 - accuracy: 0.9815 - val_loss: 0.2541 - val_accuracy: 0.9633\n",
      "Epoch 49/50\n",
      "205/205 [==============================] - 0s 596us/step - loss: 0.0464 - accuracy: 0.9826 - val_loss: 0.2562 - val_accuracy: 0.9645\n",
      "Epoch 50/50\n",
      "205/205 [==============================] - 0s 613us/step - loss: 0.0406 - accuracy: 0.9844 - val_loss: 0.2668 - val_accuracy: 0.9658\n",
      "52/52 [==============================] - 0s 290us/step\n",
      "Evaluation Metrics for Endpoint 'SR.ATAD5':\n",
      "Precision: 0.8485\n",
      "Recall: 0.3500\n",
      "F1 Score: 0.4956\n",
      "ROC-AUC: 0.8720\n",
      "Confusion Matrix:\n",
      "[[1551    5]\n",
      " [  52   28]]\n",
      "Finished processing SR.ATAD5.\n",
      "\n",
      "Processing SR.HSE...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Ratthew/anaconda3/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "187/187 [==============================] - 0s 857us/step - loss: 0.2643 - accuracy: 0.9372 - val_loss: 0.1708 - val_accuracy: 0.9530\n",
      "Epoch 2/50\n",
      "187/187 [==============================] - 0s 618us/step - loss: 0.1980 - accuracy: 0.9494 - val_loss: 0.1623 - val_accuracy: 0.9530\n",
      "Epoch 3/50\n",
      "187/187 [==============================] - 0s 617us/step - loss: 0.1740 - accuracy: 0.9516 - val_loss: 0.1564 - val_accuracy: 0.9537\n",
      "Epoch 4/50\n",
      "187/187 [==============================] - 0s 612us/step - loss: 0.1650 - accuracy: 0.9543 - val_loss: 0.1581 - val_accuracy: 0.9543\n",
      "Epoch 5/50\n",
      "187/187 [==============================] - 0s 627us/step - loss: 0.1523 - accuracy: 0.9525 - val_loss: 0.1582 - val_accuracy: 0.9537\n",
      "Epoch 6/50\n",
      "187/187 [==============================] - 0s 615us/step - loss: 0.1476 - accuracy: 0.9560 - val_loss: 0.1545 - val_accuracy: 0.9550\n",
      "Epoch 7/50\n",
      "187/187 [==============================] - 0s 616us/step - loss: 0.1499 - accuracy: 0.9543 - val_loss: 0.1547 - val_accuracy: 0.9557\n",
      "Epoch 8/50\n",
      "187/187 [==============================] - 0s 651us/step - loss: 0.1393 - accuracy: 0.9567 - val_loss: 0.1590 - val_accuracy: 0.9550\n",
      "Epoch 9/50\n",
      "187/187 [==============================] - 0s 593us/step - loss: 0.1387 - accuracy: 0.9583 - val_loss: 0.1629 - val_accuracy: 0.9537\n",
      "Epoch 10/50\n",
      "187/187 [==============================] - 0s 653us/step - loss: 0.1314 - accuracy: 0.9583 - val_loss: 0.1650 - val_accuracy: 0.9577\n",
      "Epoch 11/50\n",
      "187/187 [==============================] - 0s 679us/step - loss: 0.1325 - accuracy: 0.9570 - val_loss: 0.1632 - val_accuracy: 0.9584\n",
      "Epoch 12/50\n",
      "187/187 [==============================] - 0s 696us/step - loss: 0.1235 - accuracy: 0.9592 - val_loss: 0.1744 - val_accuracy: 0.9570\n",
      "Epoch 13/50\n",
      "187/187 [==============================] - 0s 683us/step - loss: 0.1219 - accuracy: 0.9605 - val_loss: 0.1704 - val_accuracy: 0.9570\n",
      "Epoch 14/50\n",
      "187/187 [==============================] - 0s 642us/step - loss: 0.1221 - accuracy: 0.9590 - val_loss: 0.1746 - val_accuracy: 0.9543\n",
      "Epoch 15/50\n",
      "187/187 [==============================] - 0s 631us/step - loss: 0.1213 - accuracy: 0.9593 - val_loss: 0.1745 - val_accuracy: 0.9537\n",
      "Epoch 16/50\n",
      "187/187 [==============================] - 0s 606us/step - loss: 0.1134 - accuracy: 0.9625 - val_loss: 0.1819 - val_accuracy: 0.9550\n",
      "Epoch 17/50\n",
      "187/187 [==============================] - 0s 649us/step - loss: 0.1134 - accuracy: 0.9624 - val_loss: 0.1919 - val_accuracy: 0.9570\n",
      "Epoch 18/50\n",
      "187/187 [==============================] - 0s 664us/step - loss: 0.1076 - accuracy: 0.9634 - val_loss: 0.1956 - val_accuracy: 0.9570\n",
      "Epoch 19/50\n",
      "187/187 [==============================] - 0s 675us/step - loss: 0.1095 - accuracy: 0.9634 - val_loss: 0.1918 - val_accuracy: 0.9584\n",
      "Epoch 20/50\n",
      "187/187 [==============================] - 0s 682us/step - loss: 0.1077 - accuracy: 0.9639 - val_loss: 0.1911 - val_accuracy: 0.9570\n",
      "Epoch 21/50\n",
      "187/187 [==============================] - 0s 662us/step - loss: 0.1038 - accuracy: 0.9634 - val_loss: 0.2054 - val_accuracy: 0.9557\n",
      "Epoch 22/50\n",
      "187/187 [==============================] - 0s 552us/step - loss: 0.1048 - accuracy: 0.9654 - val_loss: 0.1990 - val_accuracy: 0.9557\n",
      "Epoch 23/50\n",
      "187/187 [==============================] - 0s 596us/step - loss: 0.0996 - accuracy: 0.9656 - val_loss: 0.2066 - val_accuracy: 0.9563\n",
      "Epoch 24/50\n",
      "187/187 [==============================] - 0s 633us/step - loss: 0.0964 - accuracy: 0.9677 - val_loss: 0.2092 - val_accuracy: 0.9584\n",
      "Epoch 25/50\n",
      "187/187 [==============================] - 0s 691us/step - loss: 0.0929 - accuracy: 0.9667 - val_loss: 0.2192 - val_accuracy: 0.9557\n",
      "Epoch 26/50\n",
      "187/187 [==============================] - 0s 705us/step - loss: 0.1002 - accuracy: 0.9683 - val_loss: 0.2257 - val_accuracy: 0.9570\n",
      "Epoch 27/50\n",
      "187/187 [==============================] - 0s 689us/step - loss: 0.0945 - accuracy: 0.9662 - val_loss: 0.2258 - val_accuracy: 0.9570\n",
      "Epoch 28/50\n",
      "187/187 [==============================] - 0s 641us/step - loss: 0.0913 - accuracy: 0.9701 - val_loss: 0.2428 - val_accuracy: 0.9563\n",
      "Epoch 29/50\n",
      "187/187 [==============================] - 0s 637us/step - loss: 0.0906 - accuracy: 0.9683 - val_loss: 0.2440 - val_accuracy: 0.9584\n",
      "Epoch 30/50\n",
      "187/187 [==============================] - 0s 618us/step - loss: 0.0875 - accuracy: 0.9699 - val_loss: 0.2456 - val_accuracy: 0.9584\n",
      "Epoch 31/50\n",
      "187/187 [==============================] - 0s 666us/step - loss: 0.0882 - accuracy: 0.9709 - val_loss: 0.2407 - val_accuracy: 0.9597\n",
      "Epoch 32/50\n",
      "187/187 [==============================] - 0s 671us/step - loss: 0.0845 - accuracy: 0.9706 - val_loss: 0.2546 - val_accuracy: 0.9584\n",
      "Epoch 33/50\n",
      "187/187 [==============================] - 0s 614us/step - loss: 0.0814 - accuracy: 0.9748 - val_loss: 0.2435 - val_accuracy: 0.9590\n",
      "Epoch 34/50\n",
      "187/187 [==============================] - 0s 607us/step - loss: 0.0842 - accuracy: 0.9714 - val_loss: 0.2535 - val_accuracy: 0.9604\n",
      "Epoch 35/50\n",
      "187/187 [==============================] - 0s 621us/step - loss: 0.0853 - accuracy: 0.9711 - val_loss: 0.2540 - val_accuracy: 0.9604\n",
      "Epoch 36/50\n",
      "187/187 [==============================] - 0s 618us/step - loss: 0.0812 - accuracy: 0.9711 - val_loss: 0.2728 - val_accuracy: 0.9570\n",
      "Epoch 37/50\n",
      "187/187 [==============================] - 0s 617us/step - loss: 0.0741 - accuracy: 0.9746 - val_loss: 0.2729 - val_accuracy: 0.9570\n",
      "Epoch 38/50\n",
      "187/187 [==============================] - 0s 553us/step - loss: 0.0772 - accuracy: 0.9746 - val_loss: 0.3022 - val_accuracy: 0.9563\n",
      "Epoch 39/50\n",
      "187/187 [==============================] - 0s 572us/step - loss: 0.0807 - accuracy: 0.9748 - val_loss: 0.2706 - val_accuracy: 0.9570\n",
      "Epoch 40/50\n",
      "187/187 [==============================] - 0s 620us/step - loss: 0.0763 - accuracy: 0.9745 - val_loss: 0.2913 - val_accuracy: 0.9590\n",
      "Epoch 41/50\n",
      "187/187 [==============================] - 0s 612us/step - loss: 0.0806 - accuracy: 0.9699 - val_loss: 0.2815 - val_accuracy: 0.9577\n",
      "Epoch 42/50\n",
      "187/187 [==============================] - 0s 598us/step - loss: 0.0673 - accuracy: 0.9770 - val_loss: 0.3181 - val_accuracy: 0.9557\n",
      "Epoch 43/50\n",
      "187/187 [==============================] - 0s 638us/step - loss: 0.0677 - accuracy: 0.9767 - val_loss: 0.3253 - val_accuracy: 0.9550\n",
      "Epoch 44/50\n",
      "187/187 [==============================] - 0s 574us/step - loss: 0.0694 - accuracy: 0.9761 - val_loss: 0.3386 - val_accuracy: 0.9577\n",
      "Epoch 45/50\n",
      "187/187 [==============================] - 0s 602us/step - loss: 0.0700 - accuracy: 0.9772 - val_loss: 0.3331 - val_accuracy: 0.9557\n",
      "Epoch 46/50\n",
      "187/187 [==============================] - 0s 609us/step - loss: 0.0631 - accuracy: 0.9793 - val_loss: 0.3353 - val_accuracy: 0.9584\n",
      "Epoch 47/50\n",
      "187/187 [==============================] - 0s 645us/step - loss: 0.0728 - accuracy: 0.9745 - val_loss: 0.3316 - val_accuracy: 0.9563\n",
      "Epoch 48/50\n",
      "187/187 [==============================] - 0s 645us/step - loss: 0.0640 - accuracy: 0.9765 - val_loss: 0.3728 - val_accuracy: 0.9610\n",
      "Epoch 49/50\n",
      "187/187 [==============================] - 0s 619us/step - loss: 0.0598 - accuracy: 0.9777 - val_loss: 0.3756 - val_accuracy: 0.9597\n",
      "Epoch 50/50\n",
      "187/187 [==============================] - 0s 660us/step - loss: 0.0660 - accuracy: 0.9792 - val_loss: 0.3743 - val_accuracy: 0.9570\n",
      "47/47 [==============================] - 0s 364us/step\n",
      "Evaluation Metrics for Endpoint 'SR.HSE':\n",
      "Precision: 0.8750\n",
      "Recall: 0.2000\n",
      "F1 Score: 0.3256\n",
      "ROC-AUC: 0.7303\n",
      "Confusion Matrix:\n",
      "[[1417    2]\n",
      " [  56   14]]\n",
      "Finished processing SR.HSE.\n",
      "\n",
      "Processing SR.MMP...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Ratthew/anaconda3/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "167/167 [==============================] - 0s 1ms/step - loss: 0.4089 - accuracy: 0.8383 - val_loss: 24.8807 - val_accuracy: 0.8776\n",
      "Epoch 2/50\n",
      "167/167 [==============================] - 0s 621us/step - loss: 0.3074 - accuracy: 0.8697 - val_loss: 17.6274 - val_accuracy: 0.8851\n",
      "Epoch 3/50\n",
      "167/167 [==============================] - 0s 633us/step - loss: 0.2642 - accuracy: 0.8916 - val_loss: 12.9359 - val_accuracy: 0.8941\n",
      "Epoch 4/50\n",
      "167/167 [==============================] - 0s 690us/step - loss: 0.2565 - accuracy: 0.8922 - val_loss: 9.5678 - val_accuracy: 0.9032\n",
      "Epoch 5/50\n",
      "167/167 [==============================] - 0s 669us/step - loss: 0.2339 - accuracy: 0.9022 - val_loss: 10.5479 - val_accuracy: 0.9047\n",
      "Epoch 6/50\n",
      "167/167 [==============================] - 0s 676us/step - loss: 0.2282 - accuracy: 0.9061 - val_loss: 7.4427 - val_accuracy: 0.9062\n",
      "Epoch 7/50\n",
      "167/167 [==============================] - 0s 584us/step - loss: 0.2153 - accuracy: 0.9097 - val_loss: 11.7124 - val_accuracy: 0.9107\n",
      "Epoch 8/50\n",
      "167/167 [==============================] - 0s 660us/step - loss: 0.2117 - accuracy: 0.9125 - val_loss: 14.2040 - val_accuracy: 0.9174\n",
      "Epoch 9/50\n",
      "167/167 [==============================] - 0s 624us/step - loss: 0.2030 - accuracy: 0.9159 - val_loss: 15.5243 - val_accuracy: 0.9039\n",
      "Epoch 10/50\n",
      "167/167 [==============================] - 0s 683us/step - loss: 0.1935 - accuracy: 0.9194 - val_loss: 13.2373 - val_accuracy: 0.9167\n",
      "Epoch 11/50\n",
      "167/167 [==============================] - 0s 691us/step - loss: 0.1869 - accuracy: 0.9228 - val_loss: 22.4653 - val_accuracy: 0.9114\n",
      "Epoch 12/50\n",
      "167/167 [==============================] - 0s 642us/step - loss: 0.1846 - accuracy: 0.9202 - val_loss: 24.3148 - val_accuracy: 0.9122\n",
      "Epoch 13/50\n",
      "167/167 [==============================] - 0s 652us/step - loss: 0.1832 - accuracy: 0.9268 - val_loss: 22.9521 - val_accuracy: 0.9122\n",
      "Epoch 14/50\n",
      "167/167 [==============================] - 0s 672us/step - loss: 0.1829 - accuracy: 0.9239 - val_loss: 23.8018 - val_accuracy: 0.9114\n",
      "Epoch 15/50\n",
      "167/167 [==============================] - 0s 643us/step - loss: 0.1726 - accuracy: 0.9273 - val_loss: 25.5428 - val_accuracy: 0.9137\n",
      "Epoch 16/50\n",
      "167/167 [==============================] - 0s 660us/step - loss: 0.1712 - accuracy: 0.9292 - val_loss: 27.2982 - val_accuracy: 0.9197\n",
      "Epoch 17/50\n",
      "167/167 [==============================] - 0s 625us/step - loss: 0.1632 - accuracy: 0.9354 - val_loss: 27.2827 - val_accuracy: 0.9152\n",
      "Epoch 18/50\n",
      "167/167 [==============================] - 0s 628us/step - loss: 0.1674 - accuracy: 0.9309 - val_loss: 27.9309 - val_accuracy: 0.9099\n",
      "Epoch 19/50\n",
      "167/167 [==============================] - 0s 622us/step - loss: 0.1597 - accuracy: 0.9346 - val_loss: 28.8637 - val_accuracy: 0.9092\n",
      "Epoch 20/50\n",
      "167/167 [==============================] - 0s 522us/step - loss: 0.1519 - accuracy: 0.9365 - val_loss: 28.1045 - val_accuracy: 0.9129\n",
      "Epoch 21/50\n",
      "167/167 [==============================] - 0s 565us/step - loss: 0.1489 - accuracy: 0.9363 - val_loss: 30.9447 - val_accuracy: 0.9152\n",
      "Epoch 22/50\n",
      "167/167 [==============================] - 0s 616us/step - loss: 0.1540 - accuracy: 0.9386 - val_loss: 34.0770 - val_accuracy: 0.9122\n",
      "Epoch 23/50\n",
      "167/167 [==============================] - 0s 590us/step - loss: 0.1531 - accuracy: 0.9382 - val_loss: 38.2597 - val_accuracy: 0.9152\n",
      "Epoch 24/50\n",
      "167/167 [==============================] - 0s 588us/step - loss: 0.1413 - accuracy: 0.9431 - val_loss: 32.8571 - val_accuracy: 0.9152\n",
      "Epoch 25/50\n",
      "167/167 [==============================] - 0s 578us/step - loss: 0.1405 - accuracy: 0.9412 - val_loss: 37.9008 - val_accuracy: 0.9129\n",
      "Epoch 26/50\n",
      "167/167 [==============================] - 0s 587us/step - loss: 0.1377 - accuracy: 0.9433 - val_loss: 34.8169 - val_accuracy: 0.9189\n",
      "Epoch 27/50\n",
      "167/167 [==============================] - 0s 588us/step - loss: 0.1296 - accuracy: 0.9425 - val_loss: 45.0332 - val_accuracy: 0.9159\n",
      "Epoch 28/50\n",
      "167/167 [==============================] - 0s 578us/step - loss: 0.1303 - accuracy: 0.9474 - val_loss: 54.5919 - val_accuracy: 0.9272\n",
      "Epoch 29/50\n",
      "167/167 [==============================] - 0s 582us/step - loss: 0.1247 - accuracy: 0.9497 - val_loss: 64.3211 - val_accuracy: 0.9189\n",
      "Epoch 30/50\n",
      "167/167 [==============================] - 0s 582us/step - loss: 0.1278 - accuracy: 0.9514 - val_loss: 63.9058 - val_accuracy: 0.9174\n",
      "Epoch 31/50\n",
      "167/167 [==============================] - 0s 550us/step - loss: 0.1271 - accuracy: 0.9517 - val_loss: 64.1368 - val_accuracy: 0.9182\n",
      "Epoch 32/50\n",
      "167/167 [==============================] - 0s 588us/step - loss: 0.1235 - accuracy: 0.9489 - val_loss: 79.1445 - val_accuracy: 0.9212\n",
      "Epoch 33/50\n",
      "167/167 [==============================] - 0s 572us/step - loss: 0.1203 - accuracy: 0.9519 - val_loss: 91.7835 - val_accuracy: 0.9234\n",
      "Epoch 34/50\n",
      "167/167 [==============================] - 0s 595us/step - loss: 0.1167 - accuracy: 0.9551 - val_loss: 96.5991 - val_accuracy: 0.9204\n",
      "Epoch 35/50\n",
      "167/167 [==============================] - 0s 603us/step - loss: 0.1180 - accuracy: 0.9562 - val_loss: 93.7629 - val_accuracy: 0.9107\n",
      "Epoch 36/50\n",
      "167/167 [==============================] - 0s 599us/step - loss: 0.1198 - accuracy: 0.9532 - val_loss: 93.4453 - val_accuracy: 0.9227\n",
      "Epoch 37/50\n",
      "167/167 [==============================] - 0s 590us/step - loss: 0.1156 - accuracy: 0.9542 - val_loss: 109.5869 - val_accuracy: 0.9212\n",
      "Epoch 38/50\n",
      "167/167 [==============================] - 0s 595us/step - loss: 0.1121 - accuracy: 0.9562 - val_loss: 113.3575 - val_accuracy: 0.9197\n",
      "Epoch 39/50\n",
      "167/167 [==============================] - 0s 583us/step - loss: 0.1125 - accuracy: 0.9544 - val_loss: 127.7776 - val_accuracy: 0.9197\n",
      "Epoch 40/50\n",
      "167/167 [==============================] - 0s 587us/step - loss: 0.1061 - accuracy: 0.9579 - val_loss: 137.0619 - val_accuracy: 0.9234\n",
      "Epoch 41/50\n",
      "167/167 [==============================] - 0s 574us/step - loss: 0.1037 - accuracy: 0.9591 - val_loss: 149.6670 - val_accuracy: 0.9197\n",
      "Epoch 42/50\n",
      "167/167 [==============================] - 0s 589us/step - loss: 0.1069 - accuracy: 0.9577 - val_loss: 149.1934 - val_accuracy: 0.9219\n",
      "Epoch 43/50\n",
      "167/167 [==============================] - 0s 593us/step - loss: 0.1033 - accuracy: 0.9577 - val_loss: 153.3539 - val_accuracy: 0.9159\n",
      "Epoch 44/50\n",
      "167/167 [==============================] - 0s 583us/step - loss: 0.1062 - accuracy: 0.9600 - val_loss: 179.7053 - val_accuracy: 0.9234\n",
      "Epoch 45/50\n",
      "167/167 [==============================] - 0s 583us/step - loss: 0.1008 - accuracy: 0.9589 - val_loss: 188.6347 - val_accuracy: 0.9182\n",
      "Epoch 46/50\n",
      "167/167 [==============================] - 0s 573us/step - loss: 0.1048 - accuracy: 0.9600 - val_loss: 163.4755 - val_accuracy: 0.9234\n",
      "Epoch 47/50\n",
      "167/167 [==============================] - 0s 586us/step - loss: 0.1016 - accuracy: 0.9638 - val_loss: 184.5457 - val_accuracy: 0.9242\n",
      "Epoch 48/50\n",
      "167/167 [==============================] - 0s 590us/step - loss: 0.0985 - accuracy: 0.9639 - val_loss: 192.5869 - val_accuracy: 0.9197\n",
      "Epoch 49/50\n",
      "167/167 [==============================] - 0s 605us/step - loss: 0.0998 - accuracy: 0.9617 - val_loss: 212.1286 - val_accuracy: 0.9204\n",
      "Epoch 50/50\n",
      "167/167 [==============================] - 0s 595us/step - loss: 0.0944 - accuracy: 0.9639 - val_loss: 200.5370 - val_accuracy: 0.9189\n",
      "42/42 [==============================] - 0s 308us/step\n",
      "Evaluation Metrics for Endpoint 'SR.MMP':\n",
      "Precision: 0.8839\n",
      "Recall: 0.5931\n",
      "F1 Score: 0.7098\n",
      "ROC-AUC: 0.9439\n",
      "Confusion Matrix:\n",
      "[[1083   18]\n",
      " [  94  137]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Ratthew/anaconda3/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished processing SR.MMP.\n",
      "\n",
      "Processing SR.p53...\n",
      "Epoch 1/50\n",
      "195/195 [==============================] - 0s 819us/step - loss: 0.2732 - accuracy: 0.9245 - val_loss: 0.2066 - val_accuracy: 0.9325\n",
      "Epoch 2/50\n",
      "195/195 [==============================] - 0s 598us/step - loss: 0.2040 - accuracy: 0.9378 - val_loss: 0.1951 - val_accuracy: 0.9312\n",
      "Epoch 3/50\n",
      "195/195 [==============================] - 0s 603us/step - loss: 0.1792 - accuracy: 0.9397 - val_loss: 0.1810 - val_accuracy: 0.9364\n",
      "Epoch 4/50\n",
      "195/195 [==============================] - 0s 592us/step - loss: 0.1650 - accuracy: 0.9447 - val_loss: 0.1777 - val_accuracy: 0.9370\n",
      "Epoch 5/50\n",
      "195/195 [==============================] - 0s 611us/step - loss: 0.1521 - accuracy: 0.9470 - val_loss: 0.1733 - val_accuracy: 0.9364\n",
      "Epoch 6/50\n",
      "195/195 [==============================] - 0s 536us/step - loss: 0.1520 - accuracy: 0.9474 - val_loss: 0.1716 - val_accuracy: 0.9370\n",
      "Epoch 7/50\n",
      "195/195 [==============================] - 0s 584us/step - loss: 0.1417 - accuracy: 0.9494 - val_loss: 0.1678 - val_accuracy: 0.9409\n",
      "Epoch 8/50\n",
      "195/195 [==============================] - 0s 576us/step - loss: 0.1426 - accuracy: 0.9511 - val_loss: 0.1717 - val_accuracy: 0.9389\n",
      "Epoch 9/50\n",
      "195/195 [==============================] - 0s 575us/step - loss: 0.1365 - accuracy: 0.9523 - val_loss: 0.1664 - val_accuracy: 0.9422\n",
      "Epoch 10/50\n",
      "195/195 [==============================] - 0s 663us/step - loss: 0.1251 - accuracy: 0.9552 - val_loss: 0.1661 - val_accuracy: 0.9415\n",
      "Epoch 11/50\n",
      "195/195 [==============================] - 0s 573us/step - loss: 0.1248 - accuracy: 0.9550 - val_loss: 0.1660 - val_accuracy: 0.9409\n",
      "Epoch 12/50\n",
      "195/195 [==============================] - 0s 547us/step - loss: 0.1215 - accuracy: 0.9574 - val_loss: 0.1645 - val_accuracy: 0.9415\n",
      "Epoch 13/50\n",
      "195/195 [==============================] - 0s 561us/step - loss: 0.1182 - accuracy: 0.9605 - val_loss: 0.1599 - val_accuracy: 0.9434\n",
      "Epoch 14/50\n",
      "195/195 [==============================] - 0s 674us/step - loss: 0.1159 - accuracy: 0.9587 - val_loss: 0.1738 - val_accuracy: 0.9389\n",
      "Epoch 15/50\n",
      "195/195 [==============================] - 0s 670us/step - loss: 0.1130 - accuracy: 0.9601 - val_loss: 0.1670 - val_accuracy: 0.9402\n",
      "Epoch 16/50\n",
      "195/195 [==============================] - 0s 680us/step - loss: 0.1034 - accuracy: 0.9617 - val_loss: 0.1687 - val_accuracy: 0.9415\n",
      "Epoch 17/50\n",
      "195/195 [==============================] - 0s 608us/step - loss: 0.1020 - accuracy: 0.9635 - val_loss: 0.1632 - val_accuracy: 0.9434\n",
      "Epoch 18/50\n",
      "195/195 [==============================] - 0s 646us/step - loss: 0.1008 - accuracy: 0.9622 - val_loss: 0.1636 - val_accuracy: 0.9422\n",
      "Epoch 19/50\n",
      "195/195 [==============================] - 0s 600us/step - loss: 0.0972 - accuracy: 0.9646 - val_loss: 0.1683 - val_accuracy: 0.9447\n",
      "Epoch 20/50\n",
      "195/195 [==============================] - 0s 662us/step - loss: 0.0963 - accuracy: 0.9630 - val_loss: 0.1653 - val_accuracy: 0.9409\n",
      "Epoch 21/50\n",
      "195/195 [==============================] - 0s 671us/step - loss: 0.0979 - accuracy: 0.9664 - val_loss: 0.1720 - val_accuracy: 0.9447\n",
      "Epoch 22/50\n",
      "195/195 [==============================] - 0s 665us/step - loss: 0.0918 - accuracy: 0.9667 - val_loss: 0.1709 - val_accuracy: 0.9454\n",
      "Epoch 23/50\n",
      "195/195 [==============================] - 0s 664us/step - loss: 0.0823 - accuracy: 0.9690 - val_loss: 0.1670 - val_accuracy: 0.9479\n",
      "Epoch 24/50\n",
      "195/195 [==============================] - 0s 624us/step - loss: 0.0913 - accuracy: 0.9667 - val_loss: 0.1737 - val_accuracy: 0.9441\n",
      "Epoch 25/50\n",
      "195/195 [==============================] - 0s 594us/step - loss: 0.0851 - accuracy: 0.9682 - val_loss: 0.1761 - val_accuracy: 0.9460\n",
      "Epoch 26/50\n",
      "195/195 [==============================] - 0s 665us/step - loss: 0.0839 - accuracy: 0.9693 - val_loss: 0.1779 - val_accuracy: 0.9460\n",
      "Epoch 27/50\n",
      "195/195 [==============================] - 0s 683us/step - loss: 0.0836 - accuracy: 0.9703 - val_loss: 0.1757 - val_accuracy: 0.9454\n",
      "Epoch 28/50\n",
      "195/195 [==============================] - 0s 665us/step - loss: 0.0742 - accuracy: 0.9728 - val_loss: 0.1889 - val_accuracy: 0.9454\n",
      "Epoch 29/50\n",
      "195/195 [==============================] - 0s 677us/step - loss: 0.0806 - accuracy: 0.9720 - val_loss: 0.1838 - val_accuracy: 0.9460\n",
      "Epoch 30/50\n",
      "195/195 [==============================] - 0s 578us/step - loss: 0.0764 - accuracy: 0.9719 - val_loss: 0.1886 - val_accuracy: 0.9492\n",
      "Epoch 31/50\n",
      "195/195 [==============================] - 0s 605us/step - loss: 0.0696 - accuracy: 0.9736 - val_loss: 0.1805 - val_accuracy: 0.9499\n",
      "Epoch 32/50\n",
      "195/195 [==============================] - 0s 625us/step - loss: 0.0711 - accuracy: 0.9741 - val_loss: 0.1955 - val_accuracy: 0.9531\n",
      "Epoch 33/50\n",
      "195/195 [==============================] - 0s 630us/step - loss: 0.0692 - accuracy: 0.9740 - val_loss: 0.1879 - val_accuracy: 0.9499\n",
      "Epoch 34/50\n",
      "195/195 [==============================] - 0s 669us/step - loss: 0.0715 - accuracy: 0.9733 - val_loss: 0.2096 - val_accuracy: 0.9512\n",
      "Epoch 35/50\n",
      "195/195 [==============================] - 0s 532us/step - loss: 0.0737 - accuracy: 0.9752 - val_loss: 0.2004 - val_accuracy: 0.9473\n",
      "Epoch 36/50\n",
      "195/195 [==============================] - 0s 584us/step - loss: 0.0611 - accuracy: 0.9767 - val_loss: 0.2095 - val_accuracy: 0.9499\n",
      "Epoch 37/50\n",
      "195/195 [==============================] - 0s 604us/step - loss: 0.0603 - accuracy: 0.9757 - val_loss: 0.2115 - val_accuracy: 0.9486\n",
      "Epoch 38/50\n",
      "195/195 [==============================] - 0s 562us/step - loss: 0.0582 - accuracy: 0.9767 - val_loss: 0.2298 - val_accuracy: 0.9492\n",
      "Epoch 39/50\n",
      "195/195 [==============================] - 0s 570us/step - loss: 0.0695 - accuracy: 0.9751 - val_loss: 0.2002 - val_accuracy: 0.9505\n",
      "Epoch 40/50\n",
      "195/195 [==============================] - 0s 592us/step - loss: 0.0646 - accuracy: 0.9778 - val_loss: 0.2140 - val_accuracy: 0.9524\n",
      "Epoch 41/50\n",
      "195/195 [==============================] - 0s 591us/step - loss: 0.0604 - accuracy: 0.9775 - val_loss: 0.2229 - val_accuracy: 0.9505\n",
      "Epoch 42/50\n",
      "195/195 [==============================] - 0s 590us/step - loss: 0.0603 - accuracy: 0.9780 - val_loss: 0.2213 - val_accuracy: 0.9505\n",
      "Epoch 43/50\n",
      "195/195 [==============================] - 0s 604us/step - loss: 0.0624 - accuracy: 0.9801 - val_loss: 0.2208 - val_accuracy: 0.9505\n",
      "Epoch 44/50\n",
      "195/195 [==============================] - 0s 535us/step - loss: 0.0577 - accuracy: 0.9781 - val_loss: 0.2154 - val_accuracy: 0.9505\n",
      "Epoch 45/50\n",
      "195/195 [==============================] - 0s 584us/step - loss: 0.0562 - accuracy: 0.9814 - val_loss: 0.2330 - val_accuracy: 0.9512\n",
      "Epoch 46/50\n",
      "195/195 [==============================] - 0s 578us/step - loss: 0.0555 - accuracy: 0.9810 - val_loss: 0.2230 - val_accuracy: 0.9505\n",
      "Epoch 47/50\n",
      "195/195 [==============================] - 0s 678us/step - loss: 0.0525 - accuracy: 0.9809 - val_loss: 0.2270 - val_accuracy: 0.9518\n",
      "Epoch 48/50\n",
      "195/195 [==============================] - 0s 577us/step - loss: 0.0569 - accuracy: 0.9772 - val_loss: 0.2464 - val_accuracy: 0.9512\n",
      "Epoch 49/50\n",
      "195/195 [==============================] - 0s 656us/step - loss: 0.0497 - accuracy: 0.9810 - val_loss: 0.2600 - val_accuracy: 0.9537\n",
      "Epoch 50/50\n",
      "195/195 [==============================] - 0s 551us/step - loss: 0.0522 - accuracy: 0.9807 - val_loss: 0.2509 - val_accuracy: 0.9524\n",
      "49/49 [==============================] - 0s 271us/step\n",
      "Evaluation Metrics for Endpoint 'SR.p53':\n",
      "Precision: 0.7895\n",
      "Recall: 0.4167\n",
      "F1 Score: 0.5455\n",
      "ROC-AUC: 0.9205\n",
      "Confusion Matrix:\n",
      "[[1436   12]\n",
      " [  63   45]]\n",
      "Finished processing SR.p53.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Ratthew/anaconda3/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "for endpoint in endpoints:\n",
    "    print(f\"Processing {endpoint}...\")\n",
    "    process_endpoint(endpoint, df_ordered)\n",
    "    print(f\"Finished processing {endpoint}.\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
